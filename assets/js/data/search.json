[ { "title": "[Java] 문자열(String)을 비교하는 방법 (==, equals, compare)", "url": "/posts/Java_%EB%AC%B8%EC%9E%90%EC%97%B4(String)_%EB%B9%84%EA%B5%90%ED%95%98%EB%8A%94_%EB%B0%A9%EB%B2%95/", "categories": "Java", "tags": "Java, String, equals", "date": "2022-08-25 00:00:00 +0900", "snippet": "1. Java 에서는 == 가 아닌, equals를 사용하여 문자열이 동일한지 확인합니다. 다른 언어와는 달리 == 로 확인하지 않습니다. == 는 object 가 동일한지를 체크한다. 그렇기 때문에 해당 object가 갖고 있는 문자열이 동일하다는 것을 보장할 수 없기 떄문입니다. compare 매소드를 통해서도 문자열을 비교할 수 있습니다. equals() 는 모든 객체의 부모 클래스인 Object 에 정의되어있는 매소드입니다.public boolean equals(Object anObject) { if (this == anObject) { return true; } if (anObject instanceof String) { String anotherString = (String)anObject; int n = value.length; if (n == anotherString.value.length) { char v1[] = value; char v2[] = anotherString.value; int i = 0; while (n-- != 0) { if (v1[i] != v2[i]) return false; i++; } return true; } } return false; } String 클래스는 다음과 같이 equals()를 오버라이드하여 인자로 전달된 String의 문자열을 비교하고 있습니다. 간단히 코드를 보면 == 키워드로 객체가 갖다면 더 확인하지 않고 true를 리턴합니다, 객체가 다른 경우 인자가 String 이라면 문자열을 비교하여 동일한지 결과를 리턴합니다.2. equals() 를 사용하면서 NullPointerException 피하기 equals() 를 사용하면서 주의할 점은 다음과 같이 비교할 변수가 null 이라면 NullPointerException이 발생합니다. String first = null;String object = \"test\";logger.info(\"result : \" + first.equals(object)); // NullPointException 반대로 인자로 전달되는 객체(String object)는 null 이라도 NullPointerException 이 발생하지 않습니다. String first = \"test\";String object = null;logger.info(\"result : \" + first.equals(object)); 그리고 문자열을 비교할 때 대소문자도 비교합니다. 대소문자를 구분하지 않고 알파벳이 같은지만 보려면 equalsIgnoreCase()를 사용합니다.3. compareTo()를 이용하여 문자열 비교 compareTo() 는 두개의 문자열을 비교합니다. equals() 와 다른점은 어떤 문자가 사전 (문자시작) 적인 순서로 앞에 있는지도 리턴해 줍니다. 따라서 compareTo() 를 이용하면 리스트를 오름차순, 내림차순으로 정렬할 수 있습니다. 리턴 값은 0, 음수, 양수의 int가 리턴되며 의미는 다음과 같습니다. 0 : 두개의 문자열이 동일 양수 : compareTo() 를 호출하는 객체가 비교대상으로 들어오는 object 보다 사전적으로 순서가 앞설 때 음수 : compareTo() 를 호출하는 객체가 비교대상으로 들어오는 object 보다 사전적으로 순서가 뒤일 떄 String.class public int compareTo(String anotherString) { int len1 = value.length; int len2 = anotherString.value.length; int lim = Math.min(len1, len2); char v1[] = value; char v2[] = anotherString.value; int k = 0; while (k &lt; lim) { char c1 = v1[k]; char c2 = v2[k]; if (c1 != c2) { return c1 - c2; } k++; } return len1 - len2; } Ref.Java - 문자열(String)을 비교하는 방법 (==, equals, compare)" }, { "title": "[AWS] Amazon SES - 2022년 바뀐 UI위에서", "url": "/posts/AWS-SES(Simple_Email_Service)/", "categories": "AWS", "tags": "AWS, SES, Domain, Email", "date": "2022-08-24 00:00:00 +0900", "snippet": "Amazon SES - 2022년 바뀐 UI위에서 SES란? Simple_Email_Service 로서 메일을 자동으로 보내주는 AWS 서비스이다. API 를 통해 Email 을 자동으로 보낼 때 편리하듯 하다. 구축하면서 부딪힌 점 SES를 설정할 일이 생겨 구축 중에 서칭 및 인수인계 자료를 통해 마주치다 많이 바뀐 환경이라 당황스러웠다. 막상 다른 UI 를 마주치니, 구성되는 요소들을 이해하여 어떻게 적용해야 하는지 공부하는 시간을 가졌어야 했다. 결국 SES 는 메일을 전송해주는 서비스인데, 필요한점은 Domain 과 email 주소 ( ID@Domain ) 이며,Domain 과 ID 두개 다 생성을 해야하며, 특히 Domain 은 자신이 DNS 호스트를 공급하는 방식에 따라 CNAME 값을 추가하여 AWS 에서 자동으로 72시간 내에 인증하여 사용할 수 있게 허가를 받아야 한다. 예전 SES UI 와 현재 SES UI 비교 몇년도 부터 Amazon SES UI 가 변경된지는 모르겠지만, 내가 작업하는 22-08-23 날짜로 봤을 때는용어가 많이 바뀌고 서비스를 이용하는 탭 정보도 바뀐 것 같아 보인다. 우선 예전 자료들을 보면은보통 Domain 및 email 을 바로 등록하면서 진행하는데, 현재는 Verified identities 에서 인증을 통해 진행하는 듯하다. ( 아마 존재하지 않는 Domain 주소를 가지고 Fishing mail 을 예방하기 위해해당 로직으로 바뀐 ) 듯 해 보인다.즉, Domain 값 (www.naver.com) 처럼 존재하는 도메인 으로 들어갔을 때 존재하는지 확인을 하고,email 은 해당 도메인값이 들어가있는 email 로 보내어 인증을 하는 방식이다. ex) naver.com 도메인을 등록하고 인증이 되면 test@naver.com 메일을 등록하여 인증메일을 받아서 SES 서비스를 사용할 수 있다. =&gt; 구버전 SES UI방식 작업 순서 나의 환경은 SES - Amazon Route 53 로 구성되어 있다. AWS 접속 후 SES 를 검색하여 Amazon SES로 들어간 뒤 좌측메뉴바의 Configuration =&gt; Verified identities로 들어간다. 주황색 버튼 Create identity 를 클릭 Domain을 누른 후 지정할 도메인명 (ex: google.com ) 처럼 www는 빼고 넣는다. 그 후 각자에 맞는 설정을 한 뒤 Verifying your domain 을 진행한다. 나의 경우에는 Easy DKIM 으로 진행하였으며 해당 설정을 해주어야 CNAME 값이 생성되고,해당 값으로 인증하기 위해 이 설정을 하는듯 하다. DKIM signatures 는 Enabled 하는 것을 추천한다. ( 시지가 전송 중에 위조되거나 변경되지 않았음을 확인하는 데 도움이 된다고 한다. ) 그 후 생성된 Domain 을 들어가보면 CNAME 값이 생성되었음을 확인할 수 있다. 해당값으로 인증을 진행하는 듯 하다. 이 후에 Identity status 가 Verified 로 변경되면 이용이 가능하다. ( 최대 72시간 내에 인증이 완료된다고 한다.) 도메인 호스트를 Amazon Route 53 로 사용중이라면 (Domain 명이 있을 떄에) DKIM 셋팅이 자동으로도메인 호스트에 추가된다. Route 53 를 사용중이지 않다면 해당 CNAME 의 Name과 key 값을 Domain host 에 따로 설정해주는 작업이 필요하다.정리 및 참고 변경되기 전 SES 에서는 TXT 레코드를 가지고 사용자가 ID 소유자임을 확인했었는데,도메인의 DNS 설정(Route 53 또는 DNS HOST)에서 DKIM 을 구성하면 소유자임을 확인하여 필요없다고 합니다.=&gt; 시간이 부족하다면 TXT 레코드를 등록하여 72시간내에 시간을 절약할 수 있다. 정리하자면 SES 를 사용방법이 등록 개념 보단 사용할 Id 값 ( domain 또는 email ) 을 등록하여,DKIM 및 TXT 레코드를 가지고 인증절차를 통해 확인받아서 사용하는 개념으로 보입니다. 이러한 뒷 배경을 이해하기 위해서는 DNS 설정에 대한 개념이 필요해 보입니다. Ref https://docs.aws.amazon.com/ko_kr/ses/latest/dg/creating-identities.html#just-verify-domain-proc" }, { "title": "[용어정리] SQL VS ORM", "url": "/posts/SQL_VS_ORM/", "categories": "용어정리", "tags": "SQL, ORM", "date": "2022-08-22 00:00:00 +0900", "snippet": "SQL(Query) vs ORM(Object Relational Mapping)1.SQL(Query)SQL(Structured Query Language)은 관계형 데이터베이스의 기능을 활용하도록 설계된 언어1.1 장점 SQL을 사용하면 데이터베이스에 액세스하기 위해 타사 코드에 의존하지 않으므로 공급업체에 종속될 가능성이 없다. (DB에 종속성) SQL을 사용하면 개발자가 기본 데이터베이스에서 무슨 일이 일어나고 있는지 정확히 볼 수 있으므로 ORM을 사용할 때보다 복잡한 문제를 쉽게 해결할 수 있다. (직관적)1.2 단점 SQL의 잠재력을 최대한 활용하려면 잘못 입력하기 쉬운 복잡한 SQL 문을 작성해야 하므로 잠재력을 최대한 발휘할 수 있을 만큼 SQL에 능숙해져야 한다. 2. ORM (Object Relational Mapping)객체 지향 언어를 사용하여 데이터베이스와 상호 작용하는 방법을 제공 Java - Hibernate Python - Sqlalchemy2.1 장점 ORM을 통해 개발자는 java, python 등 원하는 언어를 계속 사용할 수 있으므로 시간을 절약하고 코드를 간소화할 수 있다. 추상화 계층을 추가하기 때문에 개발자는 MySQL, PostgreSQL, SQLite 등의 미묘한 차이점을 기억할 필요가 없다. 대신 ORM 사용에만 집중할 수 있으며 낮은 수준의 데이터베이스 상호 작용을 처리한다.(DB에 독립적)2.2 단점 ORM은 종종 라이브러리, 프레임워크 또는 API를 통해 제공되기 때문에 개발자가 ORM에 너무 의존하게 되어 다른 솔루션으로 이동하는 것이 어려워질 가능성이 항상 있다. ORM은 프레임워크가 알아서 수행하기때문에 내부에서 무슨일이 일어나는지 정확이 알기 어렵다. ORM이 제공하는 추상화는 개발자를 해당 계층으로부터 격리시켜 잠재적으로 낮은 수준의 문제 해결을 더 어렵게 만든다." }, { "title": "[Java] Java 입문 - 클래스", "url": "/posts/Java%EC%9E%85%EB%AC%B8_%ED%81%B4%EB%9E%98%EC%8A%A4/", "categories": "Java", "tags": "Java", "date": "2022-08-22 00:00:00 +0900", "snippet": " 강의 링크 : 자바 입문JAVA 입문 - 클래스Java는 객체지향 언어로 프로그램을 구성하는 요소들을 객체로 보고 객체간에 상호작용 하도록 하는것은 객체지향 프로그래밍 이라 합니다.Java는 객체를 만들기위해 클래스를 먼저 만들어야 합니다. 클래스 선언 public class 클래스명{ //...... // 클래스 블록} // 이처럼 생성한 클래스는 “붕어빵 틀”과 같고, 이것을 이용하여 만든 객체는 “붕어빵”과 같다.  Car.javapackage javaStudy;public class Car {} CarExam.javapackage javaStudy;public class CarExam {\tpublic static void main(String[] args) {\t\t// new 연산자 뒤에 있는 생성자 Car을 이용하여 메모리에 객체를 생성하라.(메모리에 생성된 객체는 인스턴스)\t\tCar c1 = new Car();\t\tCar c2 = new Car();\t\t// Car라는 객체가 두 개 만들어졌고, 만들어진 객체를 참조하는 변수 c1, c2\t}} Java의 변수 타입에는 기본형 타입과 참조형 타입이 있습니다. 기본형 타입 형태 type 논리형 boolean 문자형 char 정수형 byte, short, int, long 실수형 float, double 기본형 타입은 클래스 X  참조형 타입기본형 타입을 제외한 모든 타입(배열, 클래스 등) 기본형 타입 변수는 값을 가지고있지만, 참조형 타입 변수는 객체를 참조한다. ReferenceDataType.javapackage javaStudy;public class ReferenceDataType {\tpublic static void main(String[] args) {\t\t// 4byte 정수타입 기본형 변수에 정수 4 저장\t\tint i = 4;\t\t\t\t// 변수 앞에 참조형 타입인 String이라는 클래스가 적혀있으며, new 다음에 생성자가 있어 클래스를 메모리에 올림(인스턴스)\t\tString str = new String(\"hello\");\t\t\t\t\t\t// 기본형 변수 i는 4를 가지고있지만 참조형 변수 str은 String 객체인 \"hello\"를 참조한다.\t}}" }, { "title": "[Reference & Error] Grafana logout API(Python)", "url": "/posts/grafana_logout_api_python/", "categories": "Reference & Error", "tags": "Monitoring", "date": "2022-08-20 00:00:00 +0900", "snippet": " 참고 Post : Keycloak backchannel logout1. ReferenceGrafana 로그아웃 admin계정 ID:PW base64 Encode#admin:admin - defaultYWRtaW46YWRtaW4= Grafana사용자 목록 API를 이용하여 원하는 사용자의 번호를 얻는다참고 링크: https://grafana.com/docs/grafana/latest/developers/http_api/user/#search-usersurl = \"{gf_url}/api/users\"headers = {'Content-Type': 'application/json; charset=utf-8', 'Accept':'application/json', 'Authorization': 'Basic {admin계정 ID:PW base64 Encode}'}requests.request(\"GET\", url, headers=headers).json()# ==&gt; response = Grafana 사용자 목록 사용자 로그아웃참고 링크: https://grafana.com/docs/grafana/latest/developers/http_api/admin/#logout-userurl = \"{gf_url}/admin/users/{사용자 번호}/logout\"headers = {'Content-Type': 'application/json; charset=utf-8', 'Accept':'application/json', 'Authorization': 'Basic {admin계정 ID:PW base64 Encode}'}requests.request(\"POST\", url, headers=headers).json()# ==&gt; response = {'message': 'User logged out'}" }, { "title": "[개발 방법론] 좋은 코드 작성 원칙", "url": "/posts/%EC%A2%8B%EC%9D%80_%EC%BD%94%EB%93%9C_%EC%9E%91%EC%84%B1_%EC%9B%90%EC%B9%99/", "categories": "개발 방법론", "tags": "", "date": "2022-08-18 00:00:00 +0900", "snippet": "좋은 코드 작성 원칙 1. 간결한 코드 작성1.1 코드는 간결할수록 좋습니다. 코드가 짧을수록 오타나 단순 버그가 생길 우려가 줄고, 디버깅이 쉬워집니다.1.2 전역변수의 광범위한 사용을 줄이는 것이 좋습니다. 전역변수를 많이 사용하면, 프로그램의 흐름을 파악하기 어려워집니다. 2. 코드 재 사용2.1 코드를 모듈화 하면 좋습니다. 같은 코드가 반복된다면 함수나 클래스로 분리해 재 사용하는 것이 좋습니다. 3. 표준 라이브러리 사용3.1 표준 라이브러리를 사용하면 좋습니다 표준 라이브러리는 많이 사용되고 검증되었기 때문에 메모리 관리나 정당성 증명에 신경 쓸 필요가 없습니다. 4. 같은 형태로 프로그램 작성4.1 반복 적으로 작성하는 코드를 동일한 형태로 작성하면 좋습니다. 예를 들어 while문 대신 do while문을 사용하거나 가로, 세로를 구하는 대신 세로, 가로를 구하는 등의 변형이 아닌 자주 작성하는 알고리즘이나 코드 등은 한 번 검증된 코드를 작성하여 이를 꾸준히 사용하면 좋습니다. 5. 일관 적이고 명료한 변수 명 사용5.1 모호하지 않은 변수 명과 함수 명을 사용하면 좋습니다. 같은 코드와 함수이지만 변수 명과 함수 명을 명료하게 작성하면 좋습니다. 사용하는 언어의 표준 라이브러리에서 사용하는 명명 규칙(함수나 변수를 정하는 규칙)을 따르면 좋습니다. 6. 모든 자료 정규화6.1 같은 자료를 두 가지 형태로 저장하지 않는 것이 좋습니다. 날짜의 형태를 동일하게 맞추는 등 자료를 입력 받거나 계산하자마자 곧장 정규화 하는 것이 좋습니다. 7. 코드와 데이터 분리7.1 코드의 논리와 상관없는 데이터는 가능한 한 분리 하는 것이 좋습니다. 예를 들어 날짜의 월을 영문으로 출력해야 한다고 할 때, 각 달의 정수와 영문 이름을 배열로 선언하고 배열을 순회하면서 각 위치를 검사하는 것이 좋습니다." }, { "title": "[Java] Java 입문 - 배열", "url": "/posts/Java%EC%9E%85%EB%AC%B8_%EB%B0%B0%EC%97%B4/", "categories": "Java", "tags": "Java", "date": "2022-08-18 00:00:00 +0900", "snippet": " 강의 링크 : 자바 입문JAVA 입문 - 배열변수가 많아져 하나하나 선언하기 힘들 때 배열을 사용 ArrayExam.javapackage javaStudy;public class ArrayExam {\tpublic static void main(String[] args) {\t\t\t\t// 어떤 타입을 넣을지 타입 지정\t\t// 새로운 배열을 만들건데 몇개를 넣을 것인가\t\t\t\t// int타입 100개를 넣을 수 있는 array1 배열 생성\t\tint[] array1 = new int[100];\t\t\t\t// 인덱스는 0~99\t\tarray1[0] = 50;\t\tarray1[9] = 100;\t\tarray1[11] = 200;\t\t\t\t// 4개짜리 int형 배열을 생성했고 각각 배열에는 1,2,3,4가 들어있다.\t\tint[] array2 = new int[] {1,2,3,4};\t\t\t\t// 위와 동일\t\tint[] array3 = {1,2,3,4}; // 1차원 배열\t\t\t\tSystem.out.println(array3[2]); //3\t\t\t\tint value = array3[0];\t\t\t\tSystem.out.println(value); //1\t}}배열 사용하기 ArrayWithFor.javapackage javaStudy;public class ArrayWithFor {\tpublic static void main(String[] args) {\t\tint[] iarray = new int[100];\t\tiarray[0] = 1;\t\tiarray[1] = 2;\t\t\t\t// iarray의 0~99 인텍스에 1~100까지 수를 넣어준다.\t\tfor(int i = 0; i &lt; iarray.length; i++) {\t\t\tiarray[i] = i + 1;\t\t}\t\t\t\t// iarray의 0~99 인덱스의 값을 더하자.\t\t// 변수의 스코프 for문 처럼 감싼 변수는 그 밖에서는 아무런 문제가 없어요(변수의 스코프)\t\t// 변수 i 는 위에 for문이 시작할때 생성되었다가 위에 for문이 끝나고나서 사라졌어요~\t\tint sum = 0;\t\tfor(int i = 0; i &lt; iarray.length; i++) {\t\t\tsum = sum + iarray[i];\t\t}\t\tSystem.out.println(sum);\t\t\t}}2차원 배열 배열의 배열 ArrayExam.javapackage javaStudy;public class ArrayExam2 {\tpublic static void main(String[] args) {\t\t// 0 -&gt; 0 5 0 0\t\t// 1 -&gt; 0 0 0 0\t\t// 2 -&gt; 0 0 0 0\t\tint[][] array4 = new int[3][4];\t\tarray4[0][1] = 5;\t\t\t\t\t\t// 0 -&gt;\t\t// 1 -&gt;\t\t// 2 -&gt;\t\t// 1차원 배열이 만들어지지 않은 상태 \t\t// 이상태로 배열 안에 값을 넣으면 실행 시 오류 발생 아래와 같이 인덱스가 가르키는 배열을 추가해주어야한다.\t\tint[][] array5 = new int[3][];\t\t\t\t\t\t// 0 -&gt; 2\t\t// 1 -&gt; 0 0\t\t// 2 -&gt; 0 0 0\t\tarray5[0] = new int[1]; // 1차원 배열을 만들어주자\t\tarray5[1] = new int[2];\t\tarray5[2] = new int[3];\t\tarray5[0][0] = 2;\t\t\t\t\t\t// 위와 동일\t\tint[][] array6 = { {2},{0,0},{0,0,0} };\t\t\t\tSystem.out.println(array6[0][0]);\t\t\t\t\t\t// 다차원 배열도 위와같이 추가해서 사용하면 됨\t}}for each ForEachExam.javapackage javaStudy;public class forEachExam {\tpublic static void main(String[] args) {\t\t// java 1.5부터 ForEach 사용가능\t\tint[] iarr = {10,20,30,40,50};\t\t\t\tfor(int i = 0; i &lt; iarr.length; i++) {\t\t\tint value = iarr[i];\t\t\tSystem.out.println(value);\t\t}\t\t\t\t// ForEach =&gt; 값을 받을 변수:반복되는 자료구조를 넣어주면 됨\t\tfor(int value:iarr){\t\t\tSystem.out.println(value);\t\t}\t}}" }, { "title": "[Java] Java입문-Switch, While, do While, for", "url": "/posts/Java%EC%9E%85%EB%AC%B8_Switch_While_do_While,_for/", "categories": "Java", "tags": "Java", "date": "2022-08-15 00:00:00 +0900", "snippet": " 강의 링크 : 자바 입문JAVA 입문 - Switch, While, do While, forSwitch - 어떤 변수의 값에 따라서 실행 SwitchExam.javapackage javaStudy;public class SwitchExam {\tpublic static void main(String[] args) {\t\t// switch, case, default, break\t\t\t\tint value = 1;\t\t\t\t// case는 맞는 break 없으면 case 부터 실행, break 넣으면 그 문장만 실행\t\tswitch(value) { // JDK7이전은 정수만 가능, JDK7 이후부터는 정수, 문자열 가능\t\t\tcase 1: // 변수 value가 1 이라면 먼저 실행\t\t\t\tSystem.out.println(\"1\");\t\t\t\tbreak;\t\t\tcase 2:\t\t\t\tSystem.out.println(\"2\");\t\t\t\tbreak;\t\t\tcase 3:\t\t\t\tSystem.out.println(\"3\");\t\t\t\tbreak;\t\t\tdefault : // 1,2,3이 아닌 다른 숫자 일 경우 실행\t\t\t\tSystem.out.println(\"그 외 다른 숫자\");\t\t}\t\t\t\tString str = \"A\";\t\tswitch(str) {\t\tcase \"A\":\t\t\tSystem.out.println(\"A\");\t\t\tbreak;\t\tcase \"B\":\t\t\tSystem.out.println(\"B\");\t\t\tbreak;\t\t}\t}}반복문 - 어떠한 것을 반복적으로 사용하고 싶을 때, 상황에 ?따라 continue, break 사용 가능 while do while forwhile WhileExam.javapackage javaStudy;public class WhileExam {\tpublic static void main(String[] args) {\t\tint i = 0;\t\t\t\t// 0 ~ 9 까지 출력\t\twhile(i&lt;10) { // 조건이 그만 만족할 때 까지(i가 10보다 커질 때 까지) 반복\t\t\tSystem.out.println(i);\t\t\ti++; // i = i + 1;\t\t}\t\t\t\t// 1~100까지의 합\t\tint total = 0;\t\tint j = 1;\t\twhile(j&lt;=100) {\t\t\ttotal = total + j;\t\t\tj++; // j = j+1\t\t}\t\tSystem.out.println(total);\t\t\t\t// 아래와 같은 무한루프는 보통 조건문 추가해서 실행, 중지를 한다.\t\twhile(true) {\t\t\tSystem.out.println(\"hello\");\t\t}\t\t\t}}do while while문의 경우 조건이 만족하지 않으면 실행되지 않지만, do while문은 무조건 한번은 수행된다. DoWhileExam.java package javaStudy;import java.util.Scanner;public class DoWhileExam {\tpublic static void main(String[] args) {\t\tint value = 0;\t\tScanner scan = new Scanner(System.in); // 키보드로부터 입력받을 거애요!\t\t\t\tdo { // {}안에 있는 문장들이 실제로 반복할 문장들, 무조건 한번은 실행\t\t\tvalue = scan.nextInt(); // 입력한 값을 value에 넣을거에요!\t\t\tSystem.out.println(\"입력받은 값: \" + value);\t\t}while(value != 10); // while의 조건이 만족하지 않을 때 까지(입력받은 값이 10일때까지) do부터 반복 \t\t\t\t\tSystem.out.println(\"반복문 종료!\");\t}}for for 구문 자체에 변수 초기화, 조건식, 증감식이 한줄로 표현된다. ForExam.java package javaStudy;public class ForExam {\tpublic static void main(String[] args) {\t\tint total = 0;\t\t\t\t// 1~100의 합\t\tfor(int i = 1; i &lt;= 100; i++) { // ;으로 구분 변수초기화, 조건식, 증감식\t\t\t// 조건이 만족하면 수행\t\t\ttotal = total + i;\t\t}\t\tSystem.out.println(total);\t\t\t\t// 1~100의 짝수합\t\tint totalEven = 0;\t\tfor(int j = 1; j &lt;= 100; j++) {\t\t\tif(j % 2 != 0) {\t\t\t\tcontinue; // 만약 j가 아니면 total에 j를 더하지 말고 j를 더한 후 다음 반복\t\t\t}\t\t\ttotalEven = totalEven + 1;\t\t}\t\t\t\tint totalFif = 0;\t\tfor(int a = 0; a &lt;= 100; a++) {\t\t\ttotalFif = totalFif +1;\t\t\tif (a == 50) {\t\t\t\tbreak; // a가 50이되면 반복문을 아예 빠져나와 50까지의 합만 출력\t\t\t}\t\t}\t\t\t\tSystem.out.println(total);\t\tSystem.out.println(totalEven);\t\tSystem.out.println(totalFif);\t}}" }, { "title": "[Reference & Error] Keycloak_backchannel_logout", "url": "/posts/Keycloak_backchannel_logout/", "categories": "Reference & Error", "tags": "Keycloak", "date": "2022-08-14 00:00:00 +0900", "snippet": "1. ReferenceBack channel Logout참고 링크: OpenID Connect Backchannel Logout RP 또는 OP가 로그아웃 작업을 트리거하면 OP는 OP에서 동일한 사용자의 세션을 공유하는 모든 RP를 찾습니다. 그런 다음 OP는 각 RP에 대한 관련 클레임을 포함하는 로그아웃 토큰이라는 특수 JWT 토큰을 생성하고 모든 RP의 로그아웃 끝점에 로그아웃 토큰과 함께 로그아웃 요청을 보냅니다. 로그아웃 토큰을 받으면 RP는 토큰을 많이 검증하고 특정 사용자의 세션을 무효화합니다. RP(Relying Party) OP(OpenID Provider) Keycloak Back channel Logout참고 링크 : Keycloak Document - admin-url-configuration Keycloak Logout Token[('logout_token', 'JWT token')])] Keycloak Logout Token - decodeheader{\"alg\": \"RS256\",\"typ\": \"JWT\",\"kid\": \"\"} payload{\"iat\": ,\"jti\": \"\",\"iss\": \"{keycloakURL}/auth/realms/{Realm Name}\",\"aud\": \"{Client Name}\",\"sub\": \"{사용자 uid}\",\"typ\": \"Logout\",\"sid\": \"\",\"events\": {\"http://schemas.openid.net/event/backchannel-logout\": {},\"revoke_offline_access\": true}} {keycloakURL}/auth/realms/{REALM}/protocol/openid-connect/logout 해당 URL은 KEYCLOAK의 로그아웃 end-point이므로 로그아웃 시 해당 URL을 거쳐야 로그아웃 토큰을 생성합니다. keycloak UI Client 설정에서 backchannel Logout URL 을 입력할 수 있습니다. 해당 URL에 커스텀 API주소를 입력하면 로그아웃 시 해당 API를 호출합니다. python flask로 api를 구성했을 경우 request.values 를 이용하여 logout token을 받아올 수 있습니다.참고: keycloak-documentation Logout" }, { "title": "[Redis] Redis의 개념", "url": "/posts/Redis/", "categories": "Redis", "tags": "Redis", "date": "2022-08-13 00:00:00 +0900", "snippet": "Redis 란 무엇일까? Redis는 Open Source 이며, 데이터베이스로서 in-memory 데이터 구조 이며, 캐시, 메시지브로커, 스트리밍 엔진 기능이 있습니다. 가장 인기 있는 키, 값 스토어 입니다.REmote DIctionary Server 의 약어입니다.AWS 는 Redis 용 Amazon ElasticCache 라는 최적화된 완전관리형 데이터베이스서비스를 통해 Redis 를 지원합니다. Redis 는 NoSQL로 보이며, SQL은 데이터를 읽어오는 과정에서 DISK에 직접 접근을 하여 작동하기 떄문에시간이 소요되지만, Redis 는 메모리안에서 key-value 형태로 데이터를 가져오기 때문에 빠르게 데이터를 다룰 수 있습니다.Redis 가 제공하는 자료 구조는? 범위 쿼리로서는 String, hashes, lists, sets, sorted sets 를 제공하며,bitmaps, hyperloglogs, geospatial indexes, 그리고 streams 를 제공합니다.Redis 는 Replication, Lua scription, LRU eviction, transactions 이 내장되어 있으며 Redis Cluster와 함께 자동 파티셔닝으로 높은 유용성을 제공합니다.Redis 를 활용하자 우리는 레디스를 가지고 atomic operations 를 수행할 수 있습니다. 문자를 더하거나, 해쉬의 값을 증가시키거나, 리스트의 요소를 추가하거나 랭킹을 정렬하는 것과 같이요. 최고의 성능을 달성하기 위해 Redis는 in-memory dataset 와 함께 작업합니다. 사용 사례에 따라 Redis는 주기적으로 데이터셋을 디스크에 덤프하거나 각 명령을 디스크 기반 로그에 추가하여 데이터를 유지할 수 있습니다. 기능이 풍부한 네트워크 인메모리 캐시가 필요한 경우에도 지속성을 비활성화할 수 있습니다. 레디스는 비동기식 복제(asynchronous replication) 을 지원하고, 네트워크 분할 시 부분 재동기화를 통한 빠른 비동기화 및 자동 연결 기능을 제공합니다.또한 레디스가 포함하는 요소 Transactions Pub/Sub Keys with a limited time-to-live Automatic failover 그리고 대부분의 프로그래밍 언어로부터 레디스를 사용할 수 있습니다.Redis 의 영속성 레디스는 지속성을 보장하기 위해 데이터를 DISK 에 저장할 수 있습니다. 서버가 내려가더라도 DISK에 저장된 데이터를 읽어서 메모리에 로딩을 합니다. RDS(Snapshotting) 방식 순간적으로 메모리에 있는 내용을 DISK에 전체를 옮겨 담는 방식 AOF (Append On File) 방식 Redis의 모든 write/update 연산 자체를 모두 log 파일에 기록하는 형태 " }, { "title": "[Server] 쿠키란 무엇인가요?", "url": "/posts/%EC%BF%A0%ED%82%A4%EB%9E%80/", "categories": "Server", "tags": "Cookie", "date": "2022-08-11 00:00:00 +0900", "snippet": "요약 쿠키는 웹 브라우저가 컴퓨터에 저장하는 텍스트 파일입니다. 웹사이트를 방문할 떄,즉 서버를 방문할 때 서버는 유저가 다시 돌아올 경우를 대비하여사용자에 대한 몇가지 정보를 저장합니다. 기본적으로 쿠키는 나중에 정보를 다시 입력하는번거로움을 덜어줍니다.들어가며 오늘날 인터넷을 사용하다 보면 모든 쿠키를 허용하십니까? 라고 여부를 묻는 박스가 자주 나타납니다.게다가 묻는 내용에 대한 프라이버시 정책을 읽어보는 일은 잘 안하고 지나칩니다.쿠키란 무엇인가요? 쿠키란 웹사이트를 대신하여 컴퓨터에 저장하는 작은 파일입니다. 텍스트 파일이라고 합니다.저장하는 이유는 뭘까요? 일반적으로 쿠키는 웹 서버가 사용자를 기억할 수 있도록 도와줍니다.여러분이 웹사이트에서 작업을 수행하면, 여러분의 컴퓨터는 이를 기억합니다.이후, 다음에 방문할 때 웹사이트에 해당 정보를 전달합니다.쿠키의 유형1. 자사 쿠키본인이 학교 홈페이지(www.school.com)에 방문하였다고 가정했을 때 학교 홈페이지에서는 여러분이 로그인한 아이디로 홈페이지에 배경 및 캐릭터 설정을 할 수 있는 기능을 제공합니다. 이러한 설정을 기록하는 쿠키가 여러분의 컴퓨터에 저장됩니다.내가 작업을 다 끝내고 브라우저를 종료했다가 떠오른 일이 있어 다시 학교사이트를 방문해도내가 설정해 놓았던 배경 및 캐릭터에 색깔들이 모두 그대로 존재하며, 이는 쿠키를 기반으로해당 내역을 불러옵니다.이는 지속 쿠키(persistent cookie) 입니다. 브라우저를 종료하면 삭제되는세션 쿠키(session cookie)와 달리, 이는 여러분의 브라우저를 종료한 후에도 남아 있습니다.지속쿠키 = 자사쿠키 같은 말입니다. 이렇게 존재할 수 있는 이유는 이 쿠키를 방문한 웹사이트에서 생성하였기 때문입니다.2. 제3자 쿠키A라는 웹 사이트에서 광고를 제공한다고 생각해봅시다. B라는 웹 사이트에서도 광고를 제공하고 있습니다.A,B사이트에서 제공하는 광고는 동일한 광고주 로부터 나온 광고이며, 이 코드는 A,B 사이트에 삽입되어 있습니다.내가 만약 A, B 사이트 중 한 곳에 방문할 때, 광고주는 추적을 위해 제 3자 쿠키를 생성합니다.이 후, 내가 다른 C 라는 사이트에 방문했을 때에도 같은 광고가 나온다면,C라는 사이트에도 광고주가 제공한 광고 코드가 있는 것이며 제 3자 쿠키를 통해 나를 인식하고동일한 광고를 제공할 수 있습니다.기본적으로, 이들은 여러분의 검색 습관을 추적해 타겟팅을 위한 프로필을 생성합니다.이 때 문에 제3자 쿠키는 추적 쿠키(tracking cookies)라고도 합니다.쿠키는 어떻게 구성되나요?모든 쿠키가 동일하게 생성되지는 않으며, 우리가 앞서 살펴본 예시는 다목적 데이터 유형입니다.우리가 쿠키 내용을 자세히 살펴보면, 아래 json 데이터의 내용을 볼 수 있습니다.최소한의 개인 정보(다른 도메인과 공유되지 않음)를 포함하고 있습니다.보시는 바와 같이 일반적으로 쿠키는 키-값 쌍 시스템을 사용합니다.웹사이트에서 기록을 삭제하는 경우, 보통 쿠키도 함께 삭제합니다.쿠키를 삭제해도 사이트 데이터에는 큰 손상이 발생하지 않습니다.쿠키의 단점쿠키는 항상 개인정보 문제에 노출되어 있습니다.제3자 쿠키는 자신의 디지털 발자국을 의식하는 이들에게 특별히 문제가 될 수 있습니다. 여러분이 읽고 있었거나, 보고 있었던 것에 기반하여 웹사이트 곳곳에서 여러분을 따라다니는 광고에 불안감을 느껴보셨을 것입니다. 웹사이트에서 소셜 미디어의 “공유” 버튼 같은 것을 보신 적이 있나요? 그러한 버튼을 클릭하지 않더라도, 이들은 여러분의 활동에 관한 정보들을 제공자에게 계속해서 전달할 수 있습니다.의식하지 못한 채 민감한 데이터를 지나치게 많이 노출하는 것은 절대로 좋은 일이 아닙니다(디바이스 핑거프린팅: 얼마나 노출되어 있나요? 또한 참조해보시기 바랍니다). 데이터를 수집하는 당사자가 어떠한 악성 프로파일링에도 연루되지 않을 수 있지만, 이러한 목적으로 데이터를 사용할 수 있는 다른 이들에게 여러분의 데이터를 판매할 수도 있습니다.그러므로 요즘은 제3자 쿠키를 비활성화 하지 않을 이유가 거의 없습니다.제 3자 쿠키를 방지하는 가장 기본적인 방법은 추적 안 함(Do Not Track) 요청을 사용하는 것입니다.오늘날 많은 브라우저는 기본적으로 쿠키를 차단합니다(여러분의 브라우저 설정을 확인해 보세요). 뿐만 아니라, 원치 않는 추적을 방지하는 Privacy Badger와 Ghostery와 같은 몇 가지 플러그인과 브라우저 확장 프로그램도 존재합니다.마치며자사 쿠키는 오늘날 온라인 세계의 중요한 부분이며, 기기에 여러분의 정보를 저장하여 더 나은 사용자 경험을 제공합니다. 제3자 쿠키는 여러분에게 그다지 도움이 되지 않으며, 데이터를 수집하는 주체를 위한 것입니다. 그러나 브라우저에서 사용할 수 있는 도구를 통해 대부분 간단히 이를 차단할 수 있습니다. 출처: 쿠키란 무엇인가요?" }, { "title": "[용어정리] 동기식 비동기식", "url": "/posts/%EB%8F%99%EA%B8%B0%EC%8B%9D_%EB%B9%84%EB%8F%99%EA%B8%B0%EC%8B%9D/", "categories": "용어정리", "tags": "동기식, 비동기식", "date": "2022-08-10 00:00:00 +0900", "snippet": "데이터를 처리하는 방식에는 동기(Synchronous)와 비동기(Asynchronous)가 있습니다.1. 동기(Synchronous)동기(Sync)란 동시에 일어난다는 뜻으로, Request를 보낸 Thread는 Response가 반환될 때까지 대기해야 합니다. 경우에 따라 이러한 지연이 애플리케이션 사용자에게 지연 또는 성능저하로 인식될 수 있다.장점 동기(Sync)는 많은 프로그래밍 언어에서 잘 지원됩니다. 설계가 간단하고 직관적입니다. 코드를 한 줄씩 실행하기 때문에 의존도가 높은 코드를 처리하는데 용이합니다. 단점 결과가 반환될 때까지 대기해야 하므로 여러 요청을 처리하는데 오랜 시간이 걸립니다. 동기(Sync)는 단일 Thread 이므로 많은 요청을 처리하기 위해서는 많은 Thread가 필요합니다. 요청에 대한 반환이 늦어지는 경우 다른 요청에 영향을 줄 수 있습니다. 비디오 렌더링, 편집 또는 복잡한 수학 계산과 같은 작업을 수행하는 경우 동기(Sync) 동기 프로그래밍은 반응 시스템에서 활용 2. 비동기(Asynchronous)비동기(Async)란 동시에 수행하지 않는다는 뜻으로 Request를 보내더라도 Response의 반환여부와 상관없이 다른 요청이 가능합니다.장점 비동기(Async)는 다중 Thread이므로 프로그램을 병렬로 실행할 수 있어 더 많은 요청을 처리할 수 있습니다. 애플리케이션의 성능과 응답성을 향상시킵니다. 더 적은 리소스를 사용하므로 확장성이 띄어납니다. 단점 의존도가 높은 코드는 실행하기 어렵습니다. 비동기(Async)를 지원하는 프로그래밍 언어는 비교적 적습니다. 애플리케이션이 많은 수의 요청을 받고 비디오 편집, 사진 편집 및 데이터 처리와 같은 CPU 집약적인 작업이 없는 경우 비동기(Async) 비동기식 프로그래밍을 사용하면 동시에 더 많은 작업을 수행할 수 있으며 일반적으로 쉽고 빠르게 로드되는 흐름을 제공하여 사용자 경험을 향상시키는 데 사용" }, { "title": "[Java] Java입문-논리 연산자, 삼항 연산자", "url": "/posts/Java%EC%9E%85%EB%AC%B8_%EB%85%BC%EB%A6%AC_%EC%97%B0%EC%82%B0%EC%9E%90_%EC%82%BC%ED%95%AD_%EC%97%B0%EC%82%B0%EC%9E%90/", "categories": "Java", "tags": "Java", "date": "2022-08-10 00:00:00 +0900", "snippet": " 강의 링크 : 자바 입문JAVA 입문 - 논리 연산자, 삼항 연산자논리 연산자 논리곱(&amp;&amp;,&amp;) - 피연산자 둘 모두 true이면 true를 return 논리합(ㅣㅣ,ㅣ)  - 피연산자 둘 중 하나만 true이면 true를 return, 피연산자 둘 모두 flase이면 false return 논리부정(!) - 단항연산자, 논리부정 연산자가 앞에 있으므로 true → false, false → true 배타적 논리합 (^) - A는 true, B는 false일 경우처럼 A와B의 값이 다르면 true를 return OperatorExam4.javapackage javaStudy;public class OperatorExam4 {\tpublic static void main(String[] args) {\t\tboolean b1 = true;\t\tboolean b2 = false;\t\tboolean b3 = true;\t\t\t\t// 논리곱\t\tSystem.out.println(b1 &amp;&amp; b2); // 둘 다 ture 가 아니므로 false return\t\tSystem.out.println(b1 &amp;&amp; b3); // 둘 다 ture 이므로 ture return\t\t\t\t//논리합\t\tSystem.out.println(b1 || b2); // 둘 중 하나가 ture 이므로 true return\t\tSystem.out.println(b1 || b3); // 하나 이상이 ture 이므로 true return\t\tSystem.out.println(b2 || b2); // 둘 다 flase 이므로 false return\t\t\t\t// 사용 예\t\tint score = 88;\t\tif(score &lt;= 100 &amp;&amp; score &gt;= 70) { // score가 100보다 작거나 같고, 70보다 크거나 같을 때\t\t\tSystem.out.println(\"성공\");\t\t}else {\t\t\tSystem.out.println(\"실패\");\t\t}\t\t\t\t// 베타적 논리합\t\tSystem.out.println(b1 ^ b3); // 두값 모두 true 이므로 false return\t\tSystem.out.println(b1 ^ b2); // 값이 각각 다르므로 ture return\t\t\t\t// 부정 연산자\t\tSystem.out.println(!b1); // true 이므로 flase return \t}}삼항 연산자 OperatorExam.javapackage javaStudy;public class OperatorExam5 {\tpublic static void main(String[] args) {\t\tint b1 = (5 &gt; 4) ? 50:40; // 조건이 true면 b1=50, false면 b1=40\t\tSystem.out.println(b1); // 50\t\t\t\t// 삼항연산자는 if문으로 대체가 될 수 있다.\t\tint b2 = 0;\t\tif(5 &gt; 4) {\t\t\tb2 = 50;\t\t}else {\t\t\tb2 = 40;\t\t}\t\tSystem.out.println(b2); // 50\t}}" }, { "title": "[Java] Java입문-조건문 if문", "url": "/posts/Java%EC%9E%85%EB%AC%B8_%EC%A1%B0%EA%B1%B4%EB%AC%B8_if%EB%AC%B8/", "categories": "Java", "tags": "Java", "date": "2022-08-09 00:00:00 +0900", "snippet": " 강의 링크 : 자바 입문JAVA 입문 - 조건문 if문조건문 - 어떤 문장은 수행하고 싶고, 어떤 문장은 수행하고 싶지 않을 때 사용제어와 관련된 문법 if switch ifExam.javapackage javaStudy;public class ifExam {\tpublic static void main(String[] args) {\t\tint x = 50;\t\tint y = 60;\t\t\t\t// x가 y보다 작다면\t\tif(x &lt; y) { // 조건이 true이므로 실행\t\t\tSystem.out.println(\"x는 y보다 작습니다.\"); \t\t}\t\t\t\tif(x &gt; y) { // 조건이 false이므로 실행하지 않음\t\t\tSystem.out.println(\"x는 y보다 큽니다.\");\t\t}\t\t\t\t\t\t// 조건문 다음에 {} 로 감싸는 경우 조건이 만족되면 \t\t// {}로 감싸진 내용 모두 실행\t\tif(x == y-10) {\t\t\tSystem.out.println(\"x는 y와 같습니다.\");\t\t\tSystem.out.println(\"test\");\t\t}\t\t\t\t// 조건문 다음에 {} 로 감싸지 않은 경우 조건이 만족되면\t\t// 한 문장만 실행\t\tif(x == y)\t\t\tSystem.out.println(\"x는 y와 같습니다.\");\t\tSystem.out.println(\"test\");\t\t\t\t// if,else if,else\t\t// 가급적이면 너무 많은 else if문을 사용하지 않는것이 좋다.\t\tif(x == y) {\t\t\tSystem.out.println(\"x는 y와 같습니다.\");\t\t}else if(x &lt; y){\t\t\tSystem.out.println(\"x는 y보다 작습니다.\");\t\t}else {\t\t\tSystem.out.println(\"x와 y는 같지 않습니다.\");\t\t}\t}}" }, { "title": "[Java] Java입문-연산자와 연산식", "url": "/posts/Java%EC%9E%85%EB%AC%B8_%EC%97%B0%EC%82%B0%EC%9E%90%EC%99%80_%EC%97%B0%EC%82%B0%EC%8B%9D/", "categories": "Java", "tags": "Java", "date": "2022-08-09 00:00:00 +0900", "snippet": " 강의 링크 : 자바 입문JAVA 입문 - 연산자와 연산식연산 - 데이터를 처리하여 결과를 산출하는 것// 연산식x = y + z;// 연산자 == \"+,=\"// 피연산자 == \"x,y,z\"연산자(Operations) - 연산에 사용되는 표시나 기호 (+,-,*,/,%,=,…)피연산자(Operand) - 연산 대상이 되는 데이터 (리터럴, 변수)연산식(Expressions) - 연산자와 피연산자를 이용하여 연산의 과정을 기술한 것단항 연산자, 산술 연산자 OperatorExam.javapackage javaStudy;public class OperatorExam {\tpublic static void main(String[] args) {\t\t/*단항 연산자 - 피연산자가 하나인 연산자*/ \t\t\t\t//부호 연산자\t\tint i1 = -5;\t\tint i2 = +i1;\t\tint i3 = -i1;\t\t\t\tSystem.out.println(i1); // -5\t\tSystem.out.println(i2); // +-5 이므로 그대로 -5\t\tSystem.out.println(i3); // --5 이므로 +5\t\t\t\t//증감 연산자\t\tint i4 = ++i3; // i3 = i3+1;\t\tSystem.out.println(i4); // i3 = 5 이고, 증감 연산자가 i3 앞에 있으므로 i3+1=6, i4=6\t\tSystem.out.println(i3); // i3 = 6\t\tint i5 = i3++; // i3 = i3+1; \t\tSystem.out.println(i5); // i3 = 6 이고, 증감 연산자가 i3 뒤에 있으므로 i3이 i5에 대입된 후 i3+1\t\tSystem.out.println(i3); // i5에 6인 i3이 대입되고 1이 더해졌으므로 i3=7, i5=6\t\t\t\t//산술 연산자\t\tint i = 5;\t\tint j = 2;\t\t\t\tSystem.out.println(i+j); // 5+2=7\t\tSystem.out.println(i-j); // 5-2=3\t\tSystem.out.println(i*j); // 5*2=10\t\tSystem.out.println(i/j); // 5/2=2 // int로 선언이 되있기 때문에 정수끼리의 연산은 정수값으로만 리턴\t\tSystem.out.println(i/(double)j); // 5/2=2.5 // 피연산자 중 하나가 실수면 실수값을 리턴\t\tSystem.out.println(i%j); // 5를2로 나눈 후 나머지 값\t}}대입연산자, 비교 연산자 OperatorExam2.javapackage javaStudy;public class OperatorExam2 {\tpublic static void main(String[] args) {\t\t\t\t// 단순 대입 연산자\t\tint i = 10;\t\tint j = 10;\t\t\t\t//비교 연산자 - 비교 연산자의 결과 값은 true, false\t\tSystem.out.println(i == j); // i와 j가 같습니까? ture\t\tSystem.out.println(i != j); // i와 j가 다릅니까? false\t\tSystem.out.println(i &lt; j); // i가 j보다 작습니까? false\t\tSystem.out.println(i &lt;= j); // i가 j보다 작거나 같습니까? ture\t\tSystem.out.println(i &gt; j); // i가 j보다 큽니까? false\t\tSystem.out.println(i &gt;= j); // i가 j보다 크거나 같습니까? ture\t\t\t\t// 복합 대입 연산자\t\ti += 10; // i = i + 10;\t\tSystem.out.println(i); // 20\t\tSystem.out.println(i-=5); // i - 5 = 15\t}}연산자 우선순위 여러 연산자를 같이 쓸 때 우선순위가 높은 연산자가 먼저 쓰인다. OperatorExam3.javapackage javaStudy;public class OperatorExam3 {\tpublic static void main(String[] args) {\t\tint a = 5;\t\tint b = 10;\t\tint c = 15;\t\t\t\t//연산자 우선순위\t\t/*산술 연산자*/\t\tSystem.out.println(a - b * c); // 5 - (10 * 15) = -145\t\tSystem.out.println((a - b) * c); // (5 - 10) * 15 = -75\t\t\t\t/*논리 연산자*/\t\tSystem.out.println(a &gt; 5 &amp;&amp; b &gt; 5); // a가 5보다 크고, b가 5보다 큽니까? 둘중 하나만 참이므로 flase\t\tSystem.out.println(a &gt; 5 || b &gt; 5); // a가 5보다 크거나, b가 5보다 큽니까? 둘중 하나만 참이므로 true\t\t\t\t/*증감 연산자*/\t\tSystem.out.println(++a - 5); // 산술연산자보다 단항연산자가 위에 있으므로 (a + 1) - 5 = 1\t\tSystem.out.println(a); // 단항연산자 ++ 가 전위에 있었으므로 6\t\tSystem.out.println(a++ -5); // 단항연산자가 후위에 있을 경우 다른 연산이 먼저 수행 6 - 5 = 1\t\tSystem.out.println(a); // 단항 연산자 ++ 가 후위에 있었으므로 6 + 1 = 7 \t\t\t}}" }, { "title": "[Database] 우리는 어떤 Database를 선택하는가? ", "url": "/posts/Database_PostgreSQL_vs_MySQL/", "categories": "Database", "tags": "MySQL, PostgreSQL, Database, RDBMS, TAT", "date": "2022-08-08 00:00:00 +0900", "snippet": "우리는 어떤 DataBase를 선택하는가 ?&gt; 들어가기에 앞서.. [Side Project] TAT(This and That) 사이드 프로젝트를 진행하며 현재 설계 단계에 있다. Database를 정하고 있는데, 어떠한 DB가 우리에게 맞을까? 라는 의문을 가지고 조사하였고 해당 글을 기재하게 되었다. 1. 데이터베이스의 정의&gt; 관계형 데이터베이스란? 현재 가장 많이 사용되고 있는 데이터베이스의 한 종류입니다.테이블(table)로 이루어져 있으며, 이 테이블은 키(key)와 값(value)의 관계를 나타냅니다.이처럼 데이터의 종속성을 관계(relationship)로 표현하는 것이 관계형 데이터베이스의 특징입니다.&gt; 관계형 데이터베이스의 특징 관계형 데이터베이스의 특징은 다음과 같습니다. 데이터의 분류, 정렬, 탐색 속도가 빠릅니다. 오랫동안 사용한 만큼 신뢰성이 높고, 어떤 상황에서도 데이터의 무결성을 보장해 줍니다. 기존에 작성된 스키마를 수정하기가 어렵습니다. 데이터베이스의 부하를 분석하는 것이 어렵습니다. 출처: 관계형 데이터베이스&gt; 비관계형 데이터베이스(NoSQL) 이란? 관계형 데이터베이스 이외의 형식으로 데이터를 저장하는 데이터베이스라는 뜻입니다.즉, 관계데이터를 저장할 수 있으며 관계형 데이터베이스와 방식은 다릅니다. 스토리지 비용이 급격히 상승하면서 저장 및 쿼리를 위해 필요한 데이터 애플리케이션의 양도증가했습니다. 이러한 데이터는 정형, 반정형, 다형적 등 모양의 크기가 모두 다르기 때문에 미리 스키마를 정의하는 것이 거의 불가능해졌습니다. NoSQL 데이터베이스는 개발자가 엄청난 양의 비정형 데이터를 저장할 수 있도록 지원하여 뛰어난 유연성을 제공합니다. 출처: NoSQL이란 무엇입니까?2. TAT(This and That) 에는 어떤 Database 가 적합할까? 우리의 기획배경은 이러하다. 개발을 하는데 도움을 주는 간단한 기능들을 한 곳에 모아서 사용한다면 어떨까? 라는 생각에서 기획된 서비스이다. 그림과 같이 우리의 주제는 사용자가 올린 게시글 및 원하는 기능에 따라 상황과 경우마다 연관된 데이터가 복합적으로 연결되어 작용하는 구조이다. 결국 우리는 훗 날에 어떻게 될 지 모르겠지만 우리의 프로젝트에는 관계형데이터베이스가 더 적합해 보이며, 거대한 데이터라고는 추측되지 않기에 NoSQL 은 배제하였다. 그렇다면 어떤 관계형 데이터베이스를 써야할까?3. 어떤 RDS DB를 사용하는것이 적절할까? 많은 RDS 에는 MySQL, MariaDB, PostgreSQL 중에 고르는 것이 좋으며, 이유는 두 가지라고 한다. 가격 Amazonn Aurora(오로라) 교체 용이성 RDS의 가격은 라이센스 비용 영향을 받는다. 상용 DB인 MySQL이 오픈소스인 MariaDB, PostgreSQL 보다는 동일 사양 대비 가격이 더 높다. 프리티어 기간이 지나면 비용을 지불하면서 RDS를 사용해야하므로 미리 비용에 관련해 생각해 볼 필요가 있다. 두 번째로는 Aurora 교체 용이성이다. Amazon Aurora 는 AWS에서 MySQL과 PostgreSQL을 클라우드 기반에 맞게 재구성한 데이터베이스이다. 공식 자료에 의하면 RDS MySQL 대비 5배, PostgreSQL 보다 3배의 성능을 제공한다. 더군다나 AWS에서 직접 엔지니어링하고 있기 떄문에 계속 발전하고 있다.이렇게 보면 Aurora가 좋아보이지만 최소 월 10만 이상이기 때문에 가격에서 부담스럽다. 출처: MySQL과 MariaDB 무엇이 더 좋을까?4. 우아한형제들 기술 블로그를 접하며.. PostgreSQL 로 정하다. 우리는 해당 고민에 대한 답을 우아한형제들 기술 블로그를 접하며 답을 내릴 수 있었다.기능비교Aurora MySQL(5.7)Aurora PostgreSQL(11)commentDB특성RDBMSORDBMSPostgreSQL은 객체관계형 DBMS로 개발자는 기존 데이터 type에서 확장된 type형태를 자유롭게 정의하여 사용할 수 있다. 또한 테이블 상속기능이 제공되어 자식 테이블은 부모 테이블로부터 열을 받아 사용할 수 있다.방식멀티쓰레드멀티프로세스사용환경OLTP에 적절OLTP, OLAP에 적절단순 CRUD시에는 MySQL에 비해 PostgreSQL의 성능이 조금 떨어진다. PostgreSQL은 복잡한 쿼리를 요구하고 대규모 서비스인 경우에 특화되어 있다.MVCC지원Undo Segment 방식MGA(Multi Generation Architecture) 방식&#8211; Undo segment 방식: update 된 최신 데이터는 기존 데이터 블록의 레코드에 반영하고 변경 전 값을 undo 영역이라는 별도의 공간에 저장하여 갱신에 대한 버전관리를 하는 방식이다. &#8211; MGA 방식: 튜플을 update할 때 새로운 값으로 replace 처리하는 것이 아니라, 새로운 튜플을 추가하고 이전 튜플은 유효 범위를 마킹하여 처리하는 방식이다.UPDATE 방식UPDATEINSERT &amp; DELETE (check)PostgreSQL UPDATE시 내부적으로는 새 행이 INSERT되고 이전 데이터는 삭제 표시가 된다. 모든 인덱스에는 행의 실제 위치값에 대한 링크가 표기되어 있는데, 행이 업데이트되면 변경된 위치값에 대한 인덱스 정보도 업데이트가 필요하다. 이런 과정 때문에 UPDATE시에는 MySQL보다 성능이 떨어진다.지원되는 JOINNL JOIN HASH JOIN (5.7 2.06 ~)NL JOIN HASH JOIN SORT JOINParallel Query for SELECT지원됨 (5.7 2.09.2~)지원됨 (9.6 ~)Default Transaction IsolationREPEATABLE READREAD COMMITTED테이블 기본 구성 인덱스CLUSTERD INDEXNON-CLUSTERED INDEX “성능 개선의 key 가 될 수 있는 두 항목이 보입니다. 바로 ‘Join’과 ‘Parallel query’ 기능입니다. MySQL 8.0 에서 정식 지원되는 hash join, parallel query 기능이 저희가 사용하는 Aurora MySQL 5.7 버전에서 일부(또는 조금 다른 방식으로) 지원 되지만, 그마저도 지원불가 조건에 포함되어 활용이 쉽지 않았다고 합니다. 반면 PostgreSQL은 오래전부터(9버전~) 대부분의 select 쿼리에서 parallel 기능이 지원되고 있고 다양한 join 방식을 지원하기 때문에 개선이 필요한 정산 쿼리의 성능적인 이점을 기대해 볼 수 있을 것 같습니다. “ 라는 내용을 보았을 때 물론 우리의 프로젝트가 MariaDB 및 MySQL에서도 충분히해결해 나갈 수 있을거라고 보이지만, 좀 더 큰 이상향과 목적을 생각했을 때에는 postgreSQL이 이점이 커 보인다. 더 나아가서 1000만 건 데이터의 조인쿼리를 HASH JOIN 으로 비교 실행한 결과를 보았을 때,Aurora MySQL 에서는 22초 정도 소요되며, Aurora PostgreSQL 에서는 3초로 7배 이상 빠른 속도를 보여주었다고 한다. 따라서 개발해가며 공유데이터를 연관짓고 쿼리를 만들어가야 할 필요가 보이는 우리 프로젝트에서는 PostgreSQL 이 적합해 보인다. ( 물론, 저 정도의 데이터를 다룰 정도에 개발 인프라를 만들지는 아직 미지수이다. ) 출처: Aurora MySQL vs Aurora PostgreSQL" }, { "title": "[Java] Java입문-기본형 데이터 타입", "url": "/posts/Java%EC%9E%85%EB%AC%B8_%EA%B8%B0%EB%B3%B8%ED%98%95_%EB%8D%B0%EC%9D%B4%ED%84%B0_%ED%83%80%EC%9E%85/", "categories": "Java", "tags": "Java", "date": "2022-08-06 00:00:00 +0900", "snippet": " 강의 링크 : 자바 입문JAVA 입문 - 기본형 데이터 타입기본형 데이터 타입리터럴변수에 담은 특정한 값 자체를 의미 ex) int a = 5; (5는 정수리터럴)boolean - true, falsechar - 작은따음표로 감싼 문자 하나int - 정수long - 정수 마지막에는 알파벳 L, 좀 더 큰 정수float - 실수 마지막에는 알파벳 F, 실수double - 좀 더 큰 실수 PrimitiveDataTypeExam.javapackage javaStudy;public class PrimitiveDataTypeExam {\tpublic static void main(String[] args) {\t\t\t// boolean\t\tboolean isFun = true;\t\tSystem.out.println(isFun);\t\t\t// char\t\tchar c = 'f';\t\t\t// int\t\tint x = 59;\t\t\t// long\t\tlong bing = 1234567890l;\t\t\t// float\t\tfloat f = 32.4f;\t\t\t// double\t\tdouble d = 123456789.123;\t}}기본형의 타입변환 정수는 소수점을 담을 공간이 없으므로 실수가 정수보다 큰 타입이다. 큰 데이터 타입에 들어있는 것을 작은 데이터 타입에 넣으면 컴파일러는 오류를 발생 시킨다. (컴파일에러 - Type mismatch: cannot convert from long to int) 작은 데이터 타입에 들어있는 값을 큰 데이터 타입에 넣는 것은 상관없다.묵시적 형변환 - 선언한 타입보다 넣으려는 값의 타입이 작을 경우강제 형변환 - 선언한 타입보다 넣으려는 값의 타입이 클 경우 이지만 넣으려는 값이 선언한 타입에 충분히 들어갈 크기일 경우 TypeCastingExam.javapackage javaStudy;public class TypeCastingExam {\tpublic static void main(String[] args) {\t\t\t\t// int &lt; long 이므로 int x를 long y 에 담는 것은 가능하다.\t\t// int x 의 값이 long y에 들어갔으므로 형변환이 일어났다 할 수 있다.\t\tint x = 50000;\t\tlong y = x; // 묵시적 형변환 \t\t\t\t// int &lt; long 이므로 long x2를 int y2 에 담는 것은 불가능하다.\t\tlong x2 = 5;\t\t// int y2 = x2;\t\t// long x2의 값이 int y2에 들어갈 만큼의 크기이면 컴파일러가 알 수 있도록 \"형변환\" 한다는것을 알려주면 가능하다.\t\tint y2 = (int) x2; // 강제 형변환\t\t\t}}" }, { "title": "[Java] Java입문-개발순서,코드작성(주석, 변수, 상수)", "url": "/posts/Java%EC%9E%85%EB%AC%B8_%EA%B0%9C%EB%B0%9C%EC%88%9C%EC%84%9C_%EC%BD%94%EB%93%9C%EC%9E%91%EC%84%B1/", "categories": "Java", "tags": "Java", "date": "2022-08-06 00:00:00 +0900", "snippet": " 강의 링크 : 자바 입문JAVA 입문 - 개발순서, 코드작성(주석, 변수, 상수) JVM - 자바 코드를 실행하는 실행기JAVA 개발 순서 코드 작성 코드 컴파일 JVM으로 실행 코드작성 메모장에 HelloWorld.java 파일 생성 public class HelloWorld{\tpublic static void main(String[] args){\t\tSystem.out.println(\"Hello World\");\t}} cmd에서 HelloWorld.java 컴파일$ javac HellWorld.java// 해당 위치에 HelloWorld.class 파일이 생성되면서 컴파일 실행$ java HelloWorld 주석public class HelloWorld {\t// 프로그램의 시작 점\tpublic static void main(String[] args) {\t\tSystem.out.println(\"HelloWorld\");\t\t// System.out.println(\"test\");\t\t/* System.out.println(\"1\");\t\tSystem.out.println(\"2\");\t\tSystem.out.println(\"3\"); *///\t\tSystem.out.println(\"주석 단축키 Ctrl+/\");\t}} 행 단위 주석// code// code// code 블럭단위 주석/* code\t code\t code */ 문서화 주석/** * * @param args */eclipse java 실행 file - new - java project - finish src폴더 - new - class (java application 실행 시 module.info error 나오면 module.info 파일 삭제)변수 값(Data)를 저장할 수 있는 메모리 공간 - (값(Data)이 변할 수 있는 공간) java의 변수는 어떤 값(음식)을 담을지에 따라 맞는 변수(그릇)을 만들어 주어야 함 java는 강형 언어 - 모든 변수의 타입이 컴파일 시 결정이 되는 언어 ⇒ 따라서 처음 변수를 담을 때 어떤 변수를 담을지 정해야 함 VariabkeExam.javapackage javaStudy;public class VariableExam {\tpublic static void main(String[] args) {\t\tint count; // 변수 선언! 타입 변수명\t\t\t// 숫자를 담을 수 있는 변수를 생성했으므로 숫자는 다 담을 수 있음\t\tcount = 10;\t\t\tcount = 20;\t\t\tSystem.out.println(count);\t\t\t// count = 11.1; 정수를 담는 그릇이기 때문에 실수를 담으면 컴파일 에러가 남\t\t\tdouble avg = 11.1;\t // 실수\t\t\tString name = \"hahaha\"; // 문자열\t\t\tint totalCount; \t\t// 보통 변수 생성 시 두 단어 이상 이어질 경우 뒤에 단어의 맨 첫번째 글자는 대문자로 사용\t\t// =&gt; 카멜표기법(낙타 봉우리 같다해서 지어진 이름)\t\t}}상수 값(Data)을 담을 수 있는 메모리 공간 - (값(Data)이 변할 수 없는 공간) 상수를 선언하는 방법 - (상수를 선언할 땐 앞에 final을 붙여준다.) 상수는 대문자의 명명규칙을 사용한다. ConstantExam.javapackage javaStudy;public class ConstantExam {\tpublic static void main(String[] args) {\t\tint i;\t\ti = 10;\t\ti = 5;\t\t\t\tfinal int J;\t\tJ = 10;\t\t\t\t// J = 5; - 상수이므로 다른 값으로 선언불가\t\t\t\t/**상수 사용의 예**/\t\t// 3.14159가 뭘 의미하는지 모를 때\t\t// PI값을 틀리면 안될 때 \t\t// 변하지 않는 값인 상수로 선언\t\t\t\t/*원의 넓이 구하기*/\t\tdouble circleArea;\t\tfinal double PI = 3.14159;\t\tcircleArea = 3 * 3 * PI; // 원의 넓이\t\t\t\t/*기름 값 구하기*/\t\tfinal int OIL_PRICE = 1450; \t\t// 상수는 단어와 단어사이는 언더바(_)로 구분\t\t// 기름값이 변할 경우 변수에 들어간 1450의 값만 변경해주면 되니 리팩토링도 편하다.\t\t\t\tint totalPrice = 50 * OIL_PRICE;\t}}" }, { "title": "[Server] JWT에 대해서", "url": "/posts/JWT%EB%9E%80/", "categories": "Server", "tags": "Server, JWT", "date": "2022-08-04 00:00:00 +0900", "snippet": "1. JWT (Json Web Token) 란? JWT (Json Web Token) 란 Json 포맷을 이용하여 사용자에 대한 속성을 저장하는 Claim 기반의 Web Token 이다. JWT는 토큰 자체를 정보로 사용하는 Self-Contained 방식으로 정보를 안전하게 전달한다.클라이언트와 서버 또는 서버와 서버 사이에서도 JWT로 인증절차를 진행할 수 있다.2. JWT 구조[ JWT 구조 ] JWT는 Header, Payload, Signature 의 3 부분으로 이루어지며, Json 형태인 각 부분은 Base64Url로 인코딩 되어 표현된다. 또한 각각의 부분을 이어 주기 위해 . 구분자를 사용하여 구분한다.추가로 Base64Url는 암호화된 문자열이 아니고, 같은 문자열에 대해 항상 같은 인코딩 문자열을 반환한다. 기본형식은 아래와 같습니다. Header{ \"alg\": \"HS256\", \"typ\": \"JWT\"}Payload{ \"abc\"}1. Header(헤더) 토큰의 헤더는 typ과 alg 두 가지 정보로 구성된다. alg 는 헤더(Header)를 암호화 하는 것이 아니고, Signature를 해싱하기 위한 알고리즘을 지정하는 것이다. typ: 토큰의 타입을 지정 ex) JWT alg: 알고리즘 방식을 지정하며, 서명(Signature) 및 토큰 검증에 사용 ex) HS256(SHA256) 또는 RSA{ \"alg\": \"HS256\", \"typ\": \"JWT\"}2. PayLoad(페이로드) 토큰의 페이로드에는 토큰에서 사용할 정보의 조각들인 클레임(Claim)이 담겨있다.클레임은 총 3가지로 나누어지며, Json(Key/Value) 형태로 다수의 정보를 넣을 수 있다.2.1 등록된 클레임(Registered Claim) 등록된 클레임은 토큰 정보를 표현하기 위해 이미 정해진 종류의 데이터들로, 모두 선택적으로 작성이 가능하며 사용할 것을 권장한다. 또한 JWT를 간결하게 하기 위해 key 는 모두 길이 3의 String 이다. 여기서 subject로는 unique한 값을 사용하는데, 사용자 이메일을 주로 사용한다. iss: 토큰 발급자 (issuer) sub: 토큰 제목 (subject) aud: 토큰 대상자(audience) exp: 토큰 만료 시간(expiration), NumericDate 형식으로 되어 있어야 하 nbf: 토큰 활성 날짜(not before), 이 날이 지나기 전의 토큰은 활성화되지 않음 iat: 토큰 발급 시간(issued at), 토큰 발급 이후의 경과 시간을 알 수 있음 jti: JWT 토큰 식별자(JWT ID), 중복 방지를 위해 사용하며, 일회용 토큰(Access Token) 등에 사용 { \"iss\": \"dongdunggle\", // 발급자 \"exp\": xxx, // 토큰 만료시간 \"iat\": xxx, // 토큰 발급시간 \"sub\": \"\", // 용도별로 설정}2.2 공개 클레임(Public Claim) 공개 클레임은 사용자 정의 클레임으로, 공개용 정보를 위해 사용된다. 충돌 방지를 위해 URI 포맷을 이용하며, 예시는 아래와 같다.{ \"https://https://github.com/DonggeulDunggeul/DonggeulDunggeul.github.io\": true}2.3 비공개 클레임 (Private Claim) 비공개 클레임은 사용자 정의 클레임으로, 서버와 클라이언트 사이에 임의로 지정한 정보를 저장한다. 아래의 예시와 같다. { \"token\": lololol} 3.Signature (서명) 서명(Signature)은 토큰을 인코딩하거나 유효성 검증할 때 사용하는 고유한 암호화 코드이다. 서명(Signature)은 위에서 만든 헤더(Header)와 페이로드(Payload)의 값을 각각 BASE64Url로 인코딩하고, 인코딩한 값을 비밀 키를 이용해 헤더(Header)에서 정의한 알고리즘으로 해싱을 하고, 이 값을 다시 BASE64Url로 인코딩하여 생성한다.생성된 토크은 HTTP 통신을 할 때 Authorization 이라는 key의 value 로 사용된다. 일반적으로 value 에는 Bearer이 앞에 붙여진다. { \"Authorization\": \"Bearer {생성된 토큰 값}\",} 요청예시 &gt; curl --location --request POST'https://github.com/DonggeulDunggeul/DonggeulDunggeul.github.io \\-- header 'Accept: application/json' \\-- header 'Content-Type: application/json' \\-- header 'Authorization: Bearer JWT' \\--data-raw '{ \"name\": \"dunggeul\"} 4. JWT 단점 및 고려사항 Self-contained: 토큰 자체에 정보를 담고 있으므로 양날의 검이 될 수 있다. 토큰 길이: 토큰의 페이로드(Payload)에 정보가 많아질수록 토큰의 길이가 늘어나 네트워크에 부하를 줄 수 있다. 페이로드 자체는 암호화 된 것이 아니라 중간에 탈취시 데이터를 볼 수 있으므로 중요한 데이터는 넣지 않는다. 해킹위험이 있으므로 PayLoad 부분을 AES 암호화 알고리즘을 적용하여 패킹한다. 출처: JWT란 " }, { "title": "[Python] classmethod. instanceMethod 메모리값 차이", "url": "/posts/Python_classmethod/", "categories": "Python", "tags": "classmethod, Python", "date": "2022-08-01 00:00:00 +0900", "snippet": "파이썬 @classmethod, @staticmethod, instancemethod 에 대한 이해는해당 블로그의 글을 추천드립니다. 출처: @classmethod, @staticmethod, instancemethod @classmethod 로 정의한 매서드는 클래스를 인스턴스화 하여, 매서드를 호출 시@classmethod 의 변수값을 최우선으로 고정 시켜 작동하는 것 같음을 확인하여 공유해 봅니다.class method 일 때class Test: a = 0 @classmethod def test(cls): cls.a = 1t1 = Test()print(t1.a)t2 = Test()print(t2.a)print(Test.a)t1.test()print(t1.a)print(t2.a)print(Test.a)결과000111 마지막 print(t2.a) 의 값도 1 로 출력이 된다. 여기서 유추해볼 수 있듯이, t1, t2는 같은 클래스를 공유하고 있으며,객체이며 상속관계에 속해있다. 따라서 t1.test() 로 인스턴스화 시킨 후 classmethod 로 정의된 test 매서드를 실행할 때에Test 클래스에서 가리키는 a 의 메모리값이 1로 고정되도록 변경되기 때문에 t2.a 의 값도 1 을 출력하게 되는 것으로 보여집니다.정리하자면 python 에서 @classmethod 는 호출 시 그 클래스내에서의 python 문법 상 일반적으로 많이 쓰이는 cls(=self=Test) 로 받게되는 매개변수(본문에서 변수 a) 를 메모리에서 고정값으로 바꿔버리는 역할을 하는 듯 하다.instance method 일 때class Test: a = 0 def test(self): self.a = 1t1 = Test()print(t1.a)t2 = Test()print(t2.a)print(Test.a)t1.test()print(t1.a)print(t2.a)print(Test.a)결과2000100 print(t2.a) 의 값은 0으로서 classmethod 와 달리 변하지 않는다. t2.test()를 실행해줘야 바꿀 수 있다. 정리하자면.. @classmethod 로 정의된 매서드를 실행할 때에는 클래스내부에 있는 변수 값의 메모리값 자체가 고정적으로변하기 때문에 다른 변수로 클래스를 인스턴스화 하더라도 같이 고정된 값을 바라보게 됩니다.즉, @classmethod 는 클래스 내부에서 클래스 자체적으로 참조하는 메모리 값을 변경한다는 점을 확인할 수 있습니다. 이와 달리 Instance method 는 클래스를 인스턴스화 할 시 각각의 인스턴스로 인해 Instance method 를 불러올 때에만 변수값이 변하는 것을 확인할 수 있습니다.즉, instanceMethod 는 인스턴스 를 통해서 호출 될 시에는 메모리에 변수에 대한 새로운 참조값을 만든다는 점을 확인할 수 있습니다. " }, { "title": "[Kubernetes] Kubernetes - Volume", "url": "/posts/Kbernetes_Volume/", "categories": "Kubernetes", "tags": "Kubernetes, Volume", "date": "2022-08-01 00:00:00 +0900", "snippet": "참고: MS - Kubernetes 스토리지 관리,Kubernetes Document - 볼륨,Kubernetes Document - 퍼시스턴트 볼륨RedHat - stateful-vs-stateless,GKE - 볼륨컨테이너는 이식성이 높고, 유연하다는 특성으로 인해 스테이트리스(stateless)로 구축되었습니다. 따라서 컨테이너가 내려가거나 재시작 될 경우 기존의 데이터가 사라집니다. 경우의 따라 데이터를 보존해야할 때에는 볼륨(Volume) 을 사용하면 컨테이너가 내려가거나 재시작되어도 기존의 데이터는 유지됩니다. 스테이트풀(stateful)? 상태 정보를 저장한다.스테이트리스 트랜잭션은 단일 요청에 대해 하나의 응답이 나오므로, 자동판매기와 비슷하다. 스테이트리스(stateless)? 상태 정보를 저장하지 않는다.스테이트풀 트랜잭션은 같은 사람과 주기적으로 지속하는 대화와 비슷하다. 1. 볼륨(Volume)쿠버네티스에서의 볼륨은 쿠버네티스 리소스가 아닌 Pod의 여러 컨테이너에서 액세스할 수 있는 데이터가 있는 디렉터리를 의미합니다.컨테이너 단위가 아닌 Pod 단위이기 때문에 Pod에 여러개의 컨테이너가 공유해서 사용할 수 있습니다. 도커, 쿠버네티스 볼륨 차이 도커의 볼륨은 디스크에있는 디렉터리 디렉터리이거나 다른 컨테이너에 있다. 볼륨 드라이버를 제공하지만 기능이 다소 제한된다. 쿠버네티스는 다양한 유형의 볼륨을 지원한다.파드가 더 이상 존재하지 않으면, 쿠버네티스는 임시(ephemeral) 볼륨을 삭제하지만, 퍼시스턴트(persistent) 볼륨은 삭제하지 않는다. 볼륨의 종류와 상관없이, 파드 내의 컨테이너가 재시작되어도 데이터는 보존된다. 1.1 볼륨의 유형1.1.1 임시볼륨 emptyDirPod가 노드에 할당될 때 생성되며, 생성 당시에는 아무 내용이 없기 때문에 emptyDir라고 합니다. Pod의 컨테이너가 읽고 쓸 수 있는 빈 디렉터리를 제공합니다.Pod 안에 생성되기 때문에 Pod가 내려가거나 재시작하게되면 데이터가 없어지므로 일시적인 사용목적을 가진 데이터에 사용하기 적합합니다. 컨테이너 단위가 아닌 Pod 단위이므로 컨테이너가 내려가거나 재시작 되어도 계속해서 사용 가능 1.1.2 로컬볼륨 hostPath노드의 로컬 파일시스템을 Pod에 마운트 해서 사용합니다. 특정 노드의 파일시스템에 저장되므로 Pod가 다른 노드로 스케쥴링 되면 이전 데이터를 볼 수 없다. 1.1.3 Cloudstorage 볼륨 클라우드 서비스의 전용 스토리지를 마운트합니다. gcePersistentDisk(GCE Persistent Disk), awsElasticBlockStore(AWS EBS Volume), azureDist(MS Azure Disk Volume) 등이 있습니다. 1.1.4 파일 공유 볼륨 NFS기존 NFS (네트워크 파일 시스템) 볼륨을 파드에 마운트 할수 있습니다.Pod가 제거되어도 볼륨의 내용은 유지되고, NFS 볼륨에 데이터를 미리 채울 수 있으며, Pod 간에 데이터를 공유할 수 있습니다. 사용하려면 NFS 서버를 실행해야 한다. NFS 예시 1.1.5 분산 파일 시스템 glusterfsglusterfs 볼륨을 사용하면 Glusterfs (오픈 소스 네트워크 파일시스템) 볼륨을 파드에 마운트할 수 있습니다. gluster?Gluster / glusterfs 는 확장 가능한 분산 파일 시스템으로여러 서버의 스토리지 리소스를 단일 글로벌 네임스페이스로 활용 가능 glusterfs 예시 1.1.6 configMapconfigMap에 저장된 데이터는 볼륨에서 마운트되어 Pod에서 실행되는 컨테이너화 된 어플리케이션에서 사용됩니다. configMap을 먼저 생성해야 사용할 수 있다. 1.2 PV(PersistentVolume), PVC(PersistentVolumeClaim)PV와 PV는 Pod와 별개의 쿠버네티스 리소스로, Pod의 생명주기와 별개로 작동 합니다.PV는 스토리지의 연결을 담당하는 리소스이고, PVC는 PV와 Pod를 연결하기 위한 리소스 입니다. Kubernetes Pod에 대한 Storge 요구사항Kubernetes Pod는 스테이트리스 이지만 애플리케이션은 보통 스테이트풀입니다. Pod는 수며이 짧을 수 있고, 재시작, 이동등이 일어날 수 있으므로 Pod와 연결된 스토리지는 아래의 요구사항을 충족해야 합니다. Pod 외부에 존재해야 한다. Pod의 수명주기에 독립적이어야 한다. 모튼 Kuvernetes 노드에 엑세스 할 수 있다.  1.2.1 PV와 PVC의 라이프 사이클 ProvisioningPV를 프로비저닝할 수 있는 방법으로는 정적(static) 프로비저닝과 동적(dynamic) 프로비저닝이 있다. 정적(static) 프로비저닝 Provision storage클러스터 관리자가 스토리지를 프로비전 합니다. Claim storage스토리지를 요청하는 PVC를 배포합니다. Mount PVC to containerPVC가 PV에 바인딩 되면 PVC를 컨테이너의 경로에 마운트 할 수 있습니다. PV types - 퍼시스턴트 볼륨의 유형 동적(dynamic) 프로비저닝 Define Storage Class클러스터 관리자는 Kubernetes 클러스터의 운영 환경에 따라 스토리지 클래스를 정의합니다. Claim storage스토리지 클래스를 참조하여 PVC를 만들면 프로비저너가 호출됩니다. Provisions storage dynamically프로비저너는 새 볼륨을 생성한 후 생성한 볼륨을 나타내는 PV를 동적으로 생성합니다. Mount PVC to containerPVC가 PV에 바인딩 되면 PVC를 컨테이너의 경로에 마운트 할 수 있습니다. [주요 스토리지의 Privisioner]AWS EBS - provisioner: kubernetes.io/aws-ebsGCE PD - provisioner: kubernetes.io/gce-pdGlusterfs - provisioner: kubernetes.io/glusterfsNFS - provisioner: example.com/external-nfsOpenStack Cinder - provisioner: kubernetes.io/cindervSphere - provisioner: csi.vsphere.vmware.com / provisioner: kubernetes.io/vsphere-volumeCeph RBD - provisioner: kubernetes.io/rbdQuobyte - provisioner: kubernetes.io/quobyteAzure Disk - provisioner: kubernetes.io/azure-diskAzure File - provisioner: kubernetes.io/azure-filePortworx Volume - provisioner: kubernetes.io/portworx-volumeScaleIO - provisioner: kubernetes.io/scaleioStorageOS - provisioner: kubernetes.io/storageosLocal - provisioner: kubernetes.io/no-provisioner   Binding바인딩(Binding)은 프로비저닝으로 만든 PV를 PVC와 연결하는 단계입니다. PV와 PVC의 매핑은 1대1 관계입니다. UsingPVC는 파드에 설정되고 파드는 PVC를 볼륨으로 인식해서 사용합니다. Reclaiming사용이 끝난 PVC는 삭제되고 PVC를 사용하던 PV를 초기화(reclaim)하는 과정을 거칩니다. Reclaim Policy(초기화 정책) Retain PVC 삭제 시 사용 중이던 PV는 단순히 사용 해제 상태이므로 PV안의 데이터는 그대로 유지가 된 채로 남아 있는 상태 PV가 만약 외부 Storege와 연계되어 있었다면 PV는 삭제되더라도 외부 Storege의 볼륨은 그대로 남아 있는 상태 남아 있는 Storege의 볼륨을 삭제하거나 재 사용하려면 그 볼륨을 이용하는 PV 다시 생성 Delete PVC삭제 시 PV 또한 삭제하고 연계되어 있는 외부 Storege 쪽의 볼륨도 삭제 Provisioning할 때 동적볼륨할당으로 생성된 PV들은 기본 **Reclaim 정책은 Delete Recycle(deprecated) PV의 데이터들을 삭제하고 다시 새로운 PVC에서 PV를 사용할 수 있는 상태 기본 PV 회수 정책은 Retain, AWS, Google Cloud등과 같은 Storege Class의 경우 Dynamic Provisioning된 PV의 기본 정책은 Delete 1.2.2 PV 접근 모드 ReadWriteOnce하나의 노드에서 해당 볼륨이 읽기-쓰기로 마운트 될 수 있습니다. ReadWriteOnce 접근 모드에서도 파드가 동일 노드에서 구동되는 경우에는 복수의 파드에서 볼륨에 접근할 수 있습니다. ReadOnlyMany볼륨이 다수의 노드에서 읽기 전용으로 마운트 될 수 있습니다. ReadWriteMany 볼륨이 다수의 노드에서 읽기-쓰기로 마운트 될 수 있습니다. ReadWriteOncePod볼륨이 단일 파드에서 읽기-쓰기로 마운트될 수 있습니다. 전체 클러스터에서 단 하나의 파드만 해당 PVC를 읽거나 쓸 수 있어야하는 경우 ReadWriteOncePod 접근 모드를 사용한다. 이 기능은 CSI 볼륨과 쿠버네티스 버전 1.22+ 에서만 지원된다." }, { "title": "[Spring] Mybatis: ResultMap + LinkedHashMap", "url": "/posts/Mybatis_resultMap_linkedHashMap/", "categories": "Spring", "tags": "Spring, Mybatis", "date": "2022-07-30 00:00:00 +0900", "snippet": "HashMap ? Java Collections Framework 에 속한 구현체 클래스이면서, Map 인터페이스를 구현한 함수이다.따라서 데이터의 저장은 key, value 형태가 된다. key 값의 hash Code를 index로 Array 에 값을 저장한다.따라서 검색 속도는 매우 빠르다.그리고 해싱(Hashing) 검색을 사용하기 때문에 대용량 데이터 관리에도 좋은 성능을 보여주고 있다.key 값은 중복이 되지 않고, value 값은 허용이 된다.하지만 해시 값은 순서를 보장 하지 않는다. 예를 들어 a, b 라는 ‘key’ 값이 있을 때a =&gt; index 0, b =&gt; index 1 이렇게 순서대로 저장하지 않는다.더 자세히 보면 HashMap.keySet() 을 통하여 Set 을 꺼내게 되는데, 이 반환되는 Set 동작에서HashMap 의 데이터 입력의 순서가 정확히 보장되지 않는다.그렇기 때문에 나온 것이 LinkedHashMap 이다. 출처: HashMap(해쉬맵)에 대한 개념과 사용방법LinkedHashMap ? 즉, Hash 를 통해 자료를 보관하지만 자료를 순서대로 가져와야 하는 경우가 존재한다. =&gt; LinkedHashMap 따라서 LinkedHashMap 은 Doubly-Linked List를 내부에 유지함으로써 입력된 자료의 순서를 보관한다. 물론 자료의 크기가 커지면 메모리 사용량이 늘어나지만, 간편하다. 출처: [Java] LinkedHashMap — 순서를 유지하는 해시맵MyBatis - ResultMap 복잡한 결과 매핑을 간편하게 해주기위해 만들어진 태그[실무] ResultMap + LinkedHashMap 을 이용하여 엑셀 다운로드를 위한 데이터 를 만들다. EX1) “우리는 데이터 결과를 엑셀데이터로 만들어 반환해줄 작업이 필요하다” 는 경우에Mapper.xml 에서resultMap = animalMap SELECT TIER, NAME, GENDER FROM Member &lt;resultMap id=\"animalMap\" type=\"java.util.HashMap\"&gt; &lt;result column=\"TIER\" property=\"등급\" jdbcType=\"\"&gt; &lt;result column=\"NAME\" property=\"이름\" jdbcType=\"\"&gt; &lt;result column=\"GENDER\" property=\"성별\" jdbcType=\"\"&gt; &lt;/resultMap&gt;라는 예시코드가 있다고 가정하고 실행후 결과를 본다면 result = {이름, 등급, 성별} 이렇게 순서를 지키지 않고 들어가있는 데이터를 볼 수 있다. 하지만 엑셀에 데이터가 들어가는 순서는{등급, 이름, 성별} 순으로 들어가야 한다고 계획할 때에는 오류를 범하게 된다.따라서 LinkedHashMap이 이러한 경우에 필요하며, 타입을 수정하면resultMap = animalMap SELECT TIER, NAME, GENDER FROM Member &lt;resultMap id=\"animalMap\" type=\"java.util.LinkedHashMap\"&gt; &lt;result column=\"TIER\" property=\"등급\" jdbcType=\"\"&gt; &lt;result column=\"NAME\" property=\"이름\" jdbcType=\"\"&gt; &lt;result column=\"GENDER\" property=\"성별\" jdbcType=\"\"&gt; &lt;/resultMap&gt;내가 의도한 결과 데이터처럼 엑셀에는 result = {등급, 이름, 성별}순으로 들어가는 것을 확인할 수 있다." }, { "title": "[Kubernetes] Kubernetes - 컨피그맵, 시크릿", "url": "/posts/Kbernetes_%EC%BB%A8%ED%94%BC%EA%B7%B8%EB%A7%B5%EA%B3%BC_%EC%8B%9C%ED%81%AC%EB%A6%BF/", "categories": "Kubernetes", "tags": "Kubernetes", "date": "2022-07-28 00:00:00 +0900", "snippet": "참고 Post: Grafana Provisining - ConfigMap 생성참고: 쿠버네티스 레퍼런스 - 컨피그맵, 쿠버네티스 레퍼런스 - 시크릿,GKE - ConfigMap,GKE - Secret,ORELLY 쿠버네티스 시작하기1. 컨피그맵(ConfigMap) 과 시크릿(Secret)컨테이너 이미지는 가능한 한 재사용할 수 있게 만드는 것이 좋습니다.동일한 이미지를 개발환경, 테스트환경, 운영환경에 사용할 수 있어야 합니다.컨피그맵(ConfigMap) 과 시크릿(Secret)을 이용하면 컨테이너 이미지에서 애플리케이션 코드와 환경별 구성을 분리할 수 있어 컨테이너 이미지를 보다 범용적으로 사용할 수 있습니다. 컨피그맵(ConfigMap) 은 보안 또는 암호화를 제공하지 않으므로, 비밀번호, 키, 토큰과 같은 민감한 정보를 클러스터에서 사용하려면 시크릿(Secret) 을 사용 1.1 컨피그맵(ConfigMap)컨피그맵(ConfigMap)은 키-값 쌍으로 기밀이 아닌 데이터를 저장하는 데 사용하는 API 오브젝트로 컨테이너 환경 또는 커맨드 라인을 정의할 때 사용할 수 있는 변수의 집합으로 생각할 수 있습니다. 컨피그맵은 파드(Pod) 가 실행되기 직전에 파드와 결합이되기 때문에 컨피그맵을 이용하여 많은 어플리케이션에서 컨테이너 이미지 및 파드에 대한 정의 자체를 재사용할 수 있다. 1.1.1 컨피그맵 생성 파일 시스템 - 파일kubectl create configmap {name} \\ --from-file {file_path_1} \\ --from-file {file_path_2} 파일 시스템 - 디렉터리kubectl create configmap {name} \\ --from-file {directory_path} literal (문자)kubectl create configmap {name} \\ --from-literal={key_1}={value_1} \\ --from-literal={key_2}={value_2}   생성된 컨피그맵 출력// 생성한 컨피그맵 객체에 해당하는 YAML 출력kubectl get configmap {name} -o yaml 1.1.2 컨피그맵(ConfigMap) 사용 컨피그맵을 사용하는 세 가지 주요 방법 파일 시스템 : 키 이름에 따라 각 항목에 대한 파일 생성 환경 변수 : 환경 변수 값 동적 설정 커맨드라인 동적 생성 : 컨테이너에 대한 커맨드 라인 동적 생성 파일 시스템파드 내에 새로운 볼륨을 생성하고 해당 볼륨을 컨피그맵 볼륨으로 정의하고 마운트할 컨피그맵을 가리킵니다.apiVersion: v1kind: Podmetadata: name: {pod name}spec: containers: - name: {pod name} image: {image name} volumeMounts: - name: {name} mountPath: \"{파일이 마운트될 path}\" readOnly: true volumes: - name: {name} configmap: name: {configmap name} literal (문자)env 부분에 환경변수를 정의하면 키를 참조하여 데이터를 읽어올 수 있습니다.apiVersion: v1kind: Podmetadata: name: {pod name}spec: containers: - name: {pod name} image: {image name} command: - \"$(PARAMETER_NAME_1)\" env: - name: {PARAMETER_NAME_1} valueFrom: configMapKeyRef: name: {configmap name} key: {key_1} - name: {PARAMETER_NAME_2} valueFrom: configMapKeyRef: name: {configmap name} key: {key_2} restartPolicy: Never 커맨드 라인 인수는 환경변수를 기반으로 동작하는데 $({환경변수 이름}) 구문으로 인수를 추가할 수 있다 1.2 시크릿(Secret)시크릿은(Secret) 컨피그맵에 담기 어려운 비밀번호, 보안 토큰등 민감한 데이터를 클러스터에 저장하는 보안 객체입니다. 시크릿은 클러스터의 etcd스토리지에 평문으로 저장되므로 클러스터 관리 권한이 있는 사람은 클러스터에 위치한 모든 시크릿에 접근할 수 있다. 따라서 요구사항의 수준에 따라 쿠버네티스 시크릿은 충분한 보안성을 제공하지 않을 수 있다. 최신 버전의 쿠버네티스에서는 일반적인 클라우드 키 저장소와의 통합을 통해 사용자가 제공한 키로 시크릿을 암호화할 수 있는 기능이 추가됐다. 대부분의 클라우드 키 저장소는 쿠버네티스의 유연한 볼륨과 통합되어 있어, 클라우드 제공업체의 키 저장소를 사용할 수 있다. 1.2.1 시크릿 생성시크릿은 하나 이상의 데이터 요소를 키/값 쌍의 모음으로 유지합니다. 시크릿 생성 방법 kubectl으로 시크릿 생성 구성파일에서 시크릿 생성 사용자 커스텀 시크릿 생성 kubectl create secret {Secret_Type} {Secret_Name} {Data} Secret_Type(시크릿 유형) generic : 주로 사용되는 유형으로 로컬 파일, 디렉토리 또는 리터럴 값에서 시크릿 생성 docker-registry : Docker 레지스트리에 사용하기 위한 dockercfg 시크릿 생성, Docker 레지스트리로 인증을 수행하기위해 사용 tls : 지정된 공개 키/비공개 키 쌍에서 TLS 시크릿 생성, 공개 키/비공개 키 쌍이 이미 존재해야하며 공개 키 인증서는 PEM으로 인코딩되고 지정된 비공개 키와 일치해야 함 Data –from-file, –from-env-file : 표시된 하나 이상의 구성 파일을 포함하는 디렉터리의 경로 –from-literal : 지정되는 키/값 쌍 파일 시스템 - 파일kubectl create secret {Secret_Type} {Secret_Name} \\ --from-file {file_path_1} \\ --from-file {file_path_2} 파일 시스템 - 디렉터리kubectl create secret {Secret_Type} {Secret_Name} \\ --from-file {directory_path} literal (문자)kubectl create secret {Secret_Type} {Secret_Name} \\ --from-literal={key_1}={value_1} \\ --from-literal={key_2}={value_2}   생성된 시크릿 출력// 생성한 시크릿에 해당하는 YAML 출력kubectl get secret {Secret_Name} -o yaml 1.2.2 시크릿 사용 기존 도커 자격증명을 기반으로 시크릿 생성 및 사용 Pod에서 파일로 시크릿 사용 볼륨에서 시크릿 사용 API를 직접 호출하는 애플리케이션은 쿠버네티스 REST API를 통해 시크릿을 사용할 수 있다. 그러나 애플리케이션의 이식성을 최대한 유지하는 것을 목표로 해야하며, 쿠버네티스에서 잘 실행될 뿐만 아니라 다른 플랫폼에서도 별도의 수정 없이 실행되어야 한다. 1.3 컨피그맵(ConfigMap), 시크릿(Secret) 관리컨피그맵과 시크릿은 쿠버네티스 API를 통해 관리됩니다.1.3.1 조회// configmapkubectl get configmaps// secretkubectl get secrets// 자세한 정보kubectl describe configmap {configmap name} 1.3.2 생성- --from-file=&lt;파일 이름&gt; : 파일 이름과 동일한 시크릿 데이터 키를 사용해 파일에서 적재- --from-file=&lt;키&gt;=&lt;파일 이름&gt; : 명시적으로 지정된 시크릿 데이터 키를 사용해 파일에서 적- --from-file=&lt;디렉토리&gt; : 지정된 디렉토리 내에서 키 이름으로 사용할 수 있는 모든 파일을 적- --from-literal=&lt;키&gt;=&lt;값&gt; : 지정된 키/값 쌍을 직접 적용" }, { "title": "[Kubernetes] Kubernetes - Kubectl 명령어", "url": "/posts/Kbernetes_kubectl/", "categories": "Kubernetes", "tags": "Kubernetes", "date": "2022-07-27 00:00:00 +0900", "snippet": "참고: Kubernetes 레퍼런스 - 명령줄 도구 (Kubectl), ORELLY 쿠버네티스 시작하기1. KubectlKubectl은 쿠버네티스 API와 상호작용하기 위한 커맨드라인 도구입니다.Kubectl을 사용해 Pod, ReplicaSet 등 대부분의 쿠버네티스 객체를 관리하고, 클러스터의 전반적인 상태를 탐색하고 확인할 수 있습니다. 1.1 클러스터 상태 확인 참고) 쿠버네티스 클러스터란? 컨테이너화 된 어플리케이션을 실행하는 워커노드의 집합 1.1.1 클러스터 버전 확인쿠버네티스 API, kubectl 버전 확인이 가능합니다.$ kubectl version1.1.2 클러스터 진단클러스터를 구성하는 컴포넌트들과 클러스터의 상태를 확인 할 수 있습니다.$ kubectl get componentstatuses 참고) 쿠버네티스 컴포넌트 컨트롤 플레인(control Plane) 컴포넌트 kube-apiserver : 쿠버네티스 클러스터로 들어오는 요청(kubectl 명령 등)을 가장 앞에서 전송받아 요청의 처리 흐름에 따라 적절한 컴포넌트로 요청을 전달 etcd : 쿠버네티스 클러스터가 동작하기 위해 필요한 클러스터 및 리소스의 구성정보, 상태 정보 등을 키-값(key-value)형태로 저장하는 저장소 kube-scheduler : 새로 생성된 파드(기본적인 작업단위)를 감지하여 어떤 노드로 배치할지 결정하는 작업인 스케줄링을 담당 kube-controller-manager : kube-controller-manager는 다운된 노드가 없는지, 파드가 의도한 복제(Replicas) 숫자를 유지하고 있는지, 서비스와 파드는 적절하게 연결되어 있는지, 네임스페이스에 대한 기본 계정과 토큰이 생성되어 있는지를 확인하고 적절하지 않다면 적절한 수준을 유지하기 위해 조치하는 역할 노드(Node) 컴포넌트 kubelet : 노드에서 컨테이너가 동작하도록 관리해주는 핵심 요소로 쿠버네티스 파드를 관리하기위해 작성한 YAML을 kubectl 명령어로 적용하면, kubelet은 YAML을 통해 전달된 파드를 생성, 변경하고 YAML에 명시된 컨테이너가 정상적으로 실행되고 있는지 확인 kube-proxy : 쿠버네티스 클러스터 내부에서 네트워크 요청을 전달하는 역할로 파드의 IP는 매번 변하지만 kube-proxy가 파드에 접근할 수 있는 방법을 그때마다 관리하고 갱신하며, 서비스 오브젝트는 이 정보를 사용하여 파드가 외부에서 접근할 수 있는 경로를 제공 container runtime : 쿠버네티스가 컨테이너를 제어하기 위해 제공하는 표준 규약인 컨테이너 런타임 인터페이스(CRI)를 준수하여 쿠버네티스와 함께 사용할 수 있는 외부 애플리케이션들을 의미 CRI? : 기본적으로 쿠버네티스는 파드 관리의 역할을 하는 kubelet이 명령을 받으면 도커 런타임을 통해 컨테이너가 생성되거나 되는데 쿠버네티스 내 컨테이너 기술로 도커 이외의 것들도 사용되다보니 컨테이너 런타임에 대한 이슈가 생겼고 해당 컨테이너 런타임마다 kubelet을 수정해야 하는 문제가 생겼다. 그래서 kubelet과 컨테이너 런타임과의 표준을 정하게 되었는데 이것이 CRI(Container Runtime Interface)이다. 1.2 쿠버네티스 워커 노드 조회 1.2.1 노드 목록 조회쿠버네티스 클러스터의 모든 노드 목록을 조회할 수 있습니다.$ kubectl get nodes 쿠버네티스에서 노드는 API 서버 스케줄러 등과 같이 클러스터를 관리하는 master 노드와 컨테이너가 실행되는 worker 노드로 구분되며, 사용자 작업부하(workload)가 클러스터 전체 운영에 영향을 주지 않도록 master 노드에 스케줄링을 수행하지 않는다.1.2.2 노드 상세정보 조회특정 노드에 대한 상세 정보를 조회할 수 있습니다. 실행중인 도커, 쿠버네티스, 리눅스 커널 등 노드에 위치한 소프트웨어 정보 노드상에 위치한 파드 정보 요청된 전체 리소스 각 파드가 노드에 요청하는 CPU 및 메모리 정보$ kubectl describe nodes {node name} 1.3 공통 kubectl 커맨드 1.3.1 네임 스페이스(namespace)네임스페이스는 객체들의 집합을 담고있는 폴더로 쿠버네티스의 클러스터 객체들을 관리하기 위해 사용합니다.// 특정 namespace 참조$ kubectl {command} --namespace={namespace}// 모든 namespace 참조$ kubectl {command} --all-namespaces 참고) 초기 네임스페이스 default : 기본 네임스페이스 kube-system : 쿠버네티스 시스템에서 생성한 오브젝트를 위한 네임스페이스 kube-public : 모든 사용자(인증받지 않은 사용자도 포함)가 읽기 권한으로 접근할 수 있으며, 관례적으로 만들어져 있지만 아무 리소스도 없고, 꼭 사용해야하는 것은 아니다. kube-node-lease : kubernetes node의 가용성을 체크하기 위한 네임스페이스  1.3.2 컨텍스트(context)기본 네임스페이스를 영구적으로 변경하고 싶다면, 사용할 수 있습니다. Config 파일을 이용하여 여러 개의 클러스터에 쉽게 접근할 수 있도록 하는 것으로 주로 $HOME/.kube/config 경로에 존재하는 kubectl config 파일에 클러스터를 찾고 인증하는 방법등이 기록되어있다.// 기본 네임스페이스를 가진 새로운 context 생성$ kubectl config set-context {context name} -namespace={namespace}// 생성한 context 사용$ kubectl config user-context {context name} 1.3.3 쿠버네티스 객체 조회쿠버네티스 객체는 고유의 HTTP 경로에 존재하며, kubectl 커맨드는 해당 경로에 존재하는 쿠버네티스 객체에 접근하기 위해 HTTP 요청을 보냅니다.// 특정 pod 객체 조회$ kubectl get pods {pod name} --o// 전체 pod 조회$ kubectl get pods// 특정 객체 상세정보 조회$ kubectl describe {resource name} {객체 name} -o 플래그를 추가하면 객체의 좀더 많은 정보를 확인할 수 있다. 1.3.4 쿠버네티스 객체 생성, 수정, 삭제쿠버네티스 객체들은 JSON 또는 YAML 파일로 표현되며 해당 파일들을 사용해 쿠버네티스 서버에 객체를 생성, 수정, 삭제 할 수 있습니다.// 객체 생성$ kubectl apply -f {yaml}$ kubectl create -f {yaml}// 객체 수정 - 기존 객체와 다른 부분만 수정$ kubectl apply -f {yaml}// 대화식 편집 - 객체의 최신 상태를 내려받고 정의되어 있는 상태 편집$ kubectl edit {resource name} {객체 name}// 이전 이력 기록$ kubectl apply -f {yaml} view-last-applied apply 커맨드는 애노테이션(annotation)을 사용해 이전 config 이력을 객체안에 기록할 수 있다. edit-last-applied : 마지막 변경 상태 set-last-applied : 마지막 적용된 설정 view-last-applied : 마지막 적용된 상태 // 객체 삭제 $ kubectl delete -f {yaml}$ kubectl delete {resource name} {객체 name} 1.3.5 쿠버네티스 객체 라벨링라벨은 쿠버네티스 클러스터에서 객체를 식별하고 선택적으로 그룹화 하는데 사용됩니다.// 라벨 추가 - 라벨은 \"key=value\"의 형태$ kubectl label pods {pod name} {label}// 라벨 덮어쓰기$ kubectl label pods {pod name} {label} --overwrite//라벨 삭제$ kubectl label pods {pod name} {label key}- 1.3.6 쿠버네티스 디버깅 커맨드$ kubectl 은 디버깅 할 수 있도록 여러가지 커맨드를 제공합니다.// 현재 동작중인 컨테이너 로그 확인$ kubectl logs {pod name}// pod 안에 여러 컨테이너가 있을 경우$ kubectl logs {pod name} -c {container}// 현재 실행중인 컨테이너에 커맨드 실행 - 좀 더 자세한 디버깅을 수행할 수 있도록 대화형 셸 제공$ kubectl exec -it {pod name} --bash// 실행 중인 프로세스에 접근하여 프로세스에 입력값을 보낼 수 있다.$ kubectl attach -it {pod name}// 컨테이너에 파일 붙혀넣기, 가져오기// 컨테이너 - 로컬$ kubectl cp {pod name}:{path/to/remote/file} {path/to/local/file}// 로컬 - 컨테이너$ kubectl cp {path/to/local/file} {pod name}:{path/to/remote/file}// 네트워크를 통해 파드에 접근 - local port에서 container port로 트래픽을 전달하는 연결 생성$ kubectl port-forward {pod name} {local port}:{container port}// 클러스터의 리소스 사용 현황// 절대 단위(코어), 가용 리소스의 백분율(전테 코어 수)을 사용해 노드들의 CPU 및 메모리 사용량을 보여준다.$ kubectl top nodes// 모든 파드의 목록 및 리소스 사용량을 보여준다. - \"--all-namespaces\" 플래그를 추가하면 클러스터 내 모든 파드의 리소스 사용량을 확인할 수 있다. $ kubectl top pods 1.3.7 kubectl 도움말$ kubectl help$ kubectl help {command name}" }, { "title": "[AWS] IAM ( Identity and Access Management)", "url": "/posts/aws-IAM_Identity_and_Access_Management/", "categories": "AWS", "tags": "AWS, IAM", "date": "2022-07-27 00:00:00 +0900", "snippet": " 해당 내용은 도서 ‘당신이 지금 알아야할 AWS’ 와실무경험을 바탕으로 정리하였습니다. IAM ( Identity and Access Management) 우리가 처음 이메일로 만든 AWS 계정을 AWS 에서는“루트 계정”으로 정의합니다.이는 LinuxOS 환경을 접하신분이면 이해가 빠르실 거라 생각되며, 이 루트계정은 AWS리소스에 접근할 수 있는 권한을 가지고 있기 때문에 여러명의 사용자가 루트 계정을 사용하는 것은 보안에 좋지 않습니다.이를 위해 AWS 에서는 IAM 서비스를 제공합니다.IAM 은 루트 계정을 사용하지 않고도 각각의 사용자들이 AWS 리소스들에 접근할 수 있도록 해주며 IAM을 통해 유저, 유저 그룹을 만들어 각각의 사용자 혹은 그룹 별로 필요한 권한만을 제한적으로 부여할 수 있습니다.IAM 은 AWS 계정과 관련된 권한을 제어하고, 사용자를 관리하는 기능을 제공하는 보안 서비스이며, AWS 리소스에 대한 액세스를 안전하게 제어할 수 있는 웹 서비스입니다. IAM 특징 각 AWS 서비스 및 자원 별 사용 권한 지정 역할 및 정책을 통해 손쉽게 자세한 권환 관리 기업내 사용자 관리 시스템과 연동 지원 오프라인 기기 (MFA, 멀티팩터 인증)를 통한 인증 기능 IAM 구성IAM 구성은 크게 2가지로 구분됩니다. 먼저 사용자를 정의하는 IAM 사용자 - 그룹 - 역할과 각 사용자의 권한을 정의하는 IAM 정책으로 구성됩니다. 루트 사용자 모든 접근 권한을 가지는 가장 중요한 사용자입니다. 사용자 사용자는 부여된 정책에 한해서만 리소스에 접근할 수 있습니다. 그룹 그룹은 사용자 관리를 편리하게 하는 기능입니다. 그룹에 정의된 특별한 정책은 그룹에 속한 모든 사용자가 영향을 받고,모든 사용자를 수정할 필요 없이 간단히 그룹으로 묶어 그룹 권한을 수정할 수 있습니다. 역할 역할은 사용자와 유사하지만 비밀번호를 통해 접속할 수 없으며 그룹에 속할 수도 없습니다.사용자와 마찬가지로 정책에 한해서만 리소스에 접근할 수 있으며 정책이 부여되지 않았다면 아무것도 할 수 없습니다.또한 리소스가 다른 리소스를 사용할 때도 역할이 필요합니다. 정책정책은 AWS 리소스에 접근하기위해 권한을 허용할지 거부할지를 결정합니다. JSON 형태로 저장되며 각 그룹, 사용자, 역할에 부여할 수 있습니다. 또한 기존 AWS에서 제공하는 정책들을 이용하여 고객이 직접 관리하는 정책을 만들 수 있으며 더욱 정밀하게 설정할 수 있습니다." }, { "title": "[Monitoring] Grafana-datasource,dashboard provisioning", "url": "/posts/Grafana_datasource_dashboard_provisioning/", "categories": "Monitoring", "tags": "Monitoring, Grafana", "date": "2022-07-26 00:00:00 +0900", "snippet": "Grafana 8.5.0provisioning을 통해 datasource와 dashboard를 미리 설정해 둘 수 있으며, 동일한 dashboard를 여러 환경에 적용할 때에 용이합니다.아래의 방법은 kubernetes 환경에서 datasource,dashboard를 provisioning하여 grafana를 구성하는 방법입니다. 1. Grafana provisioning - datasource, dashboard 참고: Provision Grafana 1.1 폴더생성, 권한 변경// 폴더의 권한을 변경해주지 않으면 권한 오류가 발생합니다.mkdir /monitoring/grafana/confchmod -R 777 /monitoring/grafana/confmkdir /monitoring/grafana/datachmod -R 777 /monitoring/grafana/data 1.2 pv,pvc 생성 grafana-conf-pv.yamlapiVersion: v1kind: PersistentVolumemetadata: name: grafana-conf-pvspec: storageClassName: '' capacity: storage: 10Gi accessModes: - ReadWriteMany hostPath: path: /monitoring/grafana/conf persistentVolumeReclaimPolicy: Retain---apiVersion: v1kind: PersistentVolumeClaimmetadata: name: grafana-conf-pvcspec: storageClassName: '' capacity: accessModes: - ReadWriteMany resources: requests: storage: 10Gi garfana-data-pv.yamlapiVersion: v1kind: PersistentVolumemetadata: name: grafana-data-pvspec: storageClassName: '' capacity: storage: 50Gi accessModes: - ReadWriteMany hostPath: path: /monitoring/grafana/data persistentVolumeReclaimPolicy: Retain---apiVersion: v1kind: PersistentVolumeClaimmetadata: name: grafana-data-pvcspec: storageClassName: '' capacity: accessModes: - ReadWriteMany resources: requests: storage: 50Gi kubectl createkubectl create -f grafana-conf-pv.yamlkubectl create -f grafana-data-pv.yaml 1.3 datasource, dashboard configmap 생성 config-grafana.yamlapiVersion: v1kind: ConfigMapmetadata: name: grafana-datasourcesdata: prometheus.yaml: |- { \"apiVersion\": 1, \"datasources\": [ { \"access\":\"proxy\", \"editable\": true, \"name\": \"prometheus\", \"orgId\": 1, \"type\": \"prometheus\", \"url\": \"{url}\", \"version\": 1 } ] } config-grafana-dashboard.ymalapiVersion: v1kind: ConfigMapmetadata: name: grafana-dashboard-configdata: dashboard.yaml: |- { \"apiVersion\": 1, \"providers\": [ { \"name\": \"admin\", \"type\": \"file\", \"folder\": \"\", \"disableDeletion\": \"true\", \"allowUiUpdates\": \"true\", \"updateIntervalSeconds\": 10, \"editable\": \"true\", \"options\": { \"path\": \"/etc/grafana/provisioning/dashboards/dashboard.json\", \"foldersFromFilesStructure\": \"true\" } } ] } 참고) 옵션 설명 disableDeletion : provisioning된 dashboard를 삭제할 수 있도록 하는 옵션 allowUiUpdates : provisioning된 dashboard를 수정할 수 있도록 하는 옵션 config-grafana-dashboard-template.ymalapiVersion: v1kind: ConfigMapmetadata: name: grafana-dashboard-template namespace: {namespace} labels: grafana_dashboard: \"true\"data: dashboard.json: |- {dashboard json} 참고) grafana dashbaord export&amp;import kubectl createkubectl create -f config_grafana.yamlkubectl create -f config-grafana-dashboard.yamlkubectl create -f config-grafana-dashboard-template.yaml 1.4 deployment, svc 생성 grafana-deploy.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: grafanaspec: replicas: 1 selector: matchLabels: app: grafana template: metadata: name: grafana labels: app: grafana spec: containers: - name: grafana image: grafana/grafana:8.5.0 ports: - name: grafana containerPort: 3000 resources: limits: memory: \"2Gi\" cpu: \"1000m\" requests: memory: \"1Gi\" cpu: \"500m\" volumeMounts: - mountPath: /var/lib/grafana name: grafana-data-pv - mountPath: /etc/grafana name: grafana-conf-pv - mountPath: /etc/grafana/provisioning/datasources name: grafana-datasources - mountPath: /etc/grafana/provisioning/dashboards name: grafana-dashboard-config - mountPath: /etc/grafana/provisioning/dashboards name: grafana-dashboard-template readOnly: false volumes: - name: grafana-data-pv persistentVolumeClaim: claimName: grafana-data-pvc - name: grafana-datasources configMap: defaultMode: 420 name: grafana-datasources - name: grafana-dashboard-config configMap: defaultMode: 420 name: grafana-dashboard-config - name : grafana-dashboard-template configMap: defaultMode: 420 name: grafana-dashboard-template - name: grafana-conf-pv persistentVolumeClaim: claimName: grafana-conf-pvc grafana-svc.yamlapiVersion: v1kind: Servicemetadata: name: grafanas annotations: prometheus.io/scrape: 'true' prometheus.io/port: '3000'spec: selector: app: grafana type: ClusterIP ports: - port: 3000 targetPort: 3000 kubectl createkubectl create -f grafana-svc.yamlkubectl create -f grafana-deploy.yaml 1.5 home dashboard 설정 grafana.inidefault_home_dashboard_path = /etc/grafana/provisioning/dashboards/dashbaord.json" }, { "title": "[Docker] Docker 명령어 - docker run", "url": "/posts/Docker_%EB%AA%85%EB%A0%B9%EC%96%B4_docker_run/", "categories": "Docker", "tags": "Docker", "date": "2022-07-24 00:00:00 +0900", "snippet": " 참고: ORELLY 제대로 배우는 도커1. Docker 명령어1.1 run 명령어docker run {옵션} {이미지} {명령어} {인자}컨테이너 시작과 관련된 명령어로 지원되는 인자를 이용하여 이미지 실행, 도커파일, 네트워크, 컨테이너의 권한과 리소스 설정 등의 기능을 수행할 수 있습니다. 1.1.1  -a, –attach옵션이 정해지지 않으면 stdout과 stderr가 연결됩니다. 옵션이 지정되지 않고 컨테이너가 대화형 모드(-i)로 시작되었다면 stdin도 연결됩니다. 참고) stdin, stdout, stderr? stdin, stdout, stderr은 Linux 명령을 시작할 때 생성되는 세 개의 데이터 스트림입니다. stdin (표준 입력) - 텍스트를 입력으로 받아들임 stdout (표준 출력) - 명령에서 셸로의 텍스트 출력stderr (표준 오류) - 명령의 오류 메시지 좀 더 쉽게 풀어보자면, ls와 같은 명령어는 프로그램을 실행하고 그결과를 stdout (표준 출력) 으로 보냅니다. 프로그램 실행 중 오류가 발생하면 오류 내용을 stderr (표준 오류) 로 보냅니다. stdin (표준 입력) 으로부터 입력받은 내용을 가져옵니다.  1.1.2  -d, –detach컨테이너를 “분리(detached)” 모드로 실행합니다. 데몬모드라고도 불리우며, 컨테이너를 백그라운드로 실행시키고 컨테이너 ID를 반환합니다.컨테이너가 일반 프로세스가 아닌 데몬프로세스로 실행되어 프로세스가 끝나도 유지됩니다. 1.1.3  -i, –interactive연결되지 않은 상태라도 stdin을 열어 둔 상태로 유지합니다. (사용자가 입출력 할 수 있는 상태) 일반적으로 컨테이너 세션을 시작하기 위해서 -t와 같이 사용됩니다. 1.1.4  -t, –tty가상-TTY(일반 CLI 콘솔)를 할당합니다.일반적으로 대화형 컨테이너를 시작하기 위해서 -i 와 같이 사용됩니다. 1.1.5  –restart## 예시) 컨테이너를 시작하고, 0이 아닌 코드로 종료된 경우에 재시작을 n번 시도한다.docker run --restart onfailure:{n} {container}docker 가 종료된 컨테이너가 어떤 경우에 재시작할지 구성합니다. no: 컨테이너를 재시작 하지 않는다. always: 종료 상태에 상관업이 항상 재시작을 시도한다. on-failure: 컨테이너가 0이 아닌 상태로 종료된 경우에만 재시작을 시도한다. 참고) docker 종료 code exit code 0 : 성공적으로 종료된 경우 exit code 125 : 도커 명령어 자체가 실패한 경우 exit code 126 : 컨테이너의 커맨드가 실패한 경우 exit code 127 : 컨테이너의 커맨드가 존재하지 않는 경우 exit code 128+n : 리눅스 시그널 n에 해당하는 오류가 발생한 경우 참고) Linux 시그널 $ kill -l NO signal 설명 1 SIGHUP(HUP) 연결 끊기. 프로세스의 설정파일을 다시 읽는데 사용된다. 2 SIGINT(INT) 인터럽트 3 SIGQUIT(QUIT) 종료 4 SIGILL(ILL) 잘못된 명령 5 SIGTRAP(TRAP) 트렙 추적 6 SIGIOT(IOT) IOT 명령 7 SIGBUS(BUS) 버스 에러 8 SIGFPE(FPE) 고정소수점 예외 9 SIGKILL(KILL) 죽이기. 이 시그널은 잡히지 않는다. 10 SIGUSR1(USR1) 사용자 정의 시그널1 11 SIGSEGV(SEGV) 세그멘테이션 위반 12 SIGUSR2(USR2) 사용자 정의 시그널2 13 SIGPIPE(PIPE) 읽을 것이 없는 파이프에 대한 시그널 14 SIGALRM(ALRM) 경고 클럭 15 SIGTERM(TERM) 소프트웨어 종료 시그널, 일반적으로 kill 시그널이 전송되기 전에 전송된다. 잡히는 시그널이기 때문에 종료되는 것을 트랙할 수 있다. 16 SIGTKFLT 코프로세서 스택 실패 17 SIGCHLD(CHLD) 자식 프로세스의 상태변화 18 SIGCONT(CONT) STOP 시그널 이후 계속 진행할 때 사용. 19 SIGSTOP(STOP) 정지. 이 시그널 역시 잡을 수 없다. 20 SIGTSTP(TSTP) 키보드에 의해 발생하는 시그널로 Ctrl+Z로 생성된다. 21 SIGTTIN 백그라운드에서의 제어터미널 읽기 22 SIGTTOU 백그라운드에서의 제어터미널 쓰기 23 SIGURG 소켓에서의 긴급한 상태 24 SIGXCPU CPU 시간 제한 초과 setrlimit(2) 메뉴얼 패이지 참조 25 SIGXFSZ 파일 크기제한 초과 setrlimit(2) 메뉴얼 패이지 참조 26 SIGVTALRM 가상 시간 경고 setitimer(2) 메뉴얼 패이지 참조 27 SIGPROF 프로파일링 타이머 경고. setitimer(2) 메뉴얼 페이지 참조 28 SIGWINCH 윈도우 사이즈 변경 29 SIGIO 기술자에서 입출력이 가능함. fcntl(2) 메뉴얼 참조 30 SIGPWR 전원 실패 31 UNUSED 사용 안함  1.1.6  -e –env 예시 환경변수 docker image: bitnami/keycloak## 예시) docker run -e KEYCLOAK_ADMIN=admin -e KEYCLOAK_ADMIN_PASSWORD=password컨테이너 내부의 환경 변수들을 설정할 수 있습니다. 1.1.7  –rm컨테이너를 일회성으로 실행할 때 자주 쓰이며, 컨테이너가 종료되면 자동으로 컨테이너와 관련된 리소스(파일 시스템, 볼륨)까지 삭제합니다. 1.1.8  -h –hostname컨테이너의 호스트 이름을 설정합니다. hostname은 네트워크로 연결된 서버, 컴퓨터들을 구분하기 위한 이름입니다. 1.1.9  –name컨테이너에 이름을 할당하여 다른 도커 명령어에서 해당 컨테이너를 찾을 때 사용합니다. 1.1.10  -v, –volume 볼륨을 컨테이너에 마운트 할 때 사용합니다. 참고) Docker의 데이터 관리 - 볼륨의 종류 1. Bind Mount호스트 환경의 특정 경로를 컨테이너 내부 볼륨 경로와 연결하여 마운트합니다. // 예시 - 호스트에 있는 /home/adrian/data 디렉토리를 컨테이너 안에 /data라는 이름으로 마운트 시킵니다.$ docker run -v /home/adrian/adta:/data debiann ls /data 컨테이너에 설정파일 등 기존의 데이터를 제공할 때 용이합니다.   2. Volume(Docker에서 권고하는 방식)Docker 엔진이 관리하는 호스트 환경의 도커 스토리지 디렉토리(/var/lib/docker/volumes/)에 새 디렉토리를 생성하여 컨테이너 내부의 볼륨 데이터를 저장하는 방식 입니다. // 예시 - 컨테이너 내부의 /data디렉터리가 볼륨으로 만들어지고, 해당 디렉터리 내부에서 가지고 있는 모든 파일은 볼륨으로 복사됩니다.$ docker run -it --name container-test -h CONTAINER -v /data debian /bin bash // 호스트에서 볼륨 위치 확인$ docker inspect -f container-test 어플리케이션이 데이터를 생성하는 경우 즉 이미지에 의해 데이터가 채워지는 경우 용이합니다.   파일을 직접 편집해야 할 일이 많다면 바인트 마운트를, 그렇지 않다면 볼륨 마운트를 사용   3. Tmpfs Mount컨테이너 내부에 저장된 볼륨을 호스트의 파일 시스템이 아닌, 메모리에 저장하는 방식 입니다. 컨테이너가 살아있는 동안에만 메모리에 저장되어 있기 때문에 데이터를 유지하지 않으려는 경우에 적합합니다.   volume 또는 bind mounts 사용 시, 유의사항 컨테이너 내에 파일 또는 디렉토리가 존재할 때 bind mount 또는 비어있지 않은 volume을 마운트 할 경우 컨테이너에 기존에 존재하던 파일 또는 디렉토리가 마운트에 의해 가려지게 됩니다.가려진 파일들은 제거되거나 대체된것은 아니지만 마운트 되어있는 동안은 접근할 수 없습니다.(usb를 마운트 하는것처럼 컨테이너에 볼륨을 마운트 한다고 생각하면 쉽습니다. ??) 호스트 또는 컨테이너에 해당 디렉토리가 없으면 새로 생성합니다.  1.1.11  –volumes-from지정된 컨테이너의 볼륨을 마운트 합니다." }, { "title": "[Reference & Error] Keycloak local setting(Window)", "url": "/posts/Keycloak_Local_setting_for_window/", "categories": "Reference & Error", "tags": "Keycloak", "date": "2022-07-23 00:00:00 +0900", "snippet": " 관련 Post : Grafana Keycloak 연동1. Reference 1.1 Docker desktop 설치 Docker Desktop 설치 및 파이썬 스크립트 이미지 생성 1.2 Keylcoak Image Pull https://hub.docker.com/r/bitnami/keycloak/docker pull bitnami/keycloak 1.3 Docker compose yaml 실행 참고 Docker-compose.yamlversion: '2'services: postgresql: image: docker.io/bitnami/postgresql:11 environment: # ALLOW_EMPTY_PASSWORD is recommended only for development. - ALLOW_EMPTY_PASSWORD=yes - POSTGRESQL_USERNAME=bn_keycloak - POSTGRESQL_DATABASE=bitnami_keycloak volumes: - 'postgresql_data:/bitnami/postgresql' keycloak: image: docker.io/bitnami/keycloak:18 depends_on: - postgresql ports: - \"{port}:8080\"volumes: postgresql_data: driver: local 1.4. keycloak 접속 URL: localhost:{port} ID: user PW: bitnami" }, { "title": "[Reference & Error] Keycloak API, helm install, custom", "url": "/posts/Keycloak_API/", "categories": "Reference & Error", "tags": "Keycloak", "date": "2022-07-23 00:00:00 +0900", "snippet": " 관련 Post : Keycloak local setting(Window)1. Reference 1.1 Keycloak API For Python Keycloak API - PostmanKeycloak API - docimport requestsimport json Keycloak admin token 발행(Keycloak API를 호출하기 위해서는 Keycloak admin 계정의 Token이 필요합니다.)def create_token(): url = \"{}/auth/realms/{}/protocol/openid-connect/token\".format(keycloak_url, realm) payload='grant_type=password&amp;username={}&amp;password={}&amp;client_id=admin-cli'.format(keycloak_admin, keycloak_password) headers = { 'Content-Type': 'application/x-www-form-urlencoded' } response = requests.request(\"POST\", url, headers=headers, data=payload) token=json.loads(response.text)[\"access_token\"] return token realm 생성def create_realm(token): url = \"{}/auth/admin/realms\".format(keycloak_url, realm) auth = token payload = json.dumps({ \"realm\": \"{}\".format(realm), \"enabled\": \"true\", \"displayNameHtml\": '&lt;div class=\"kc-logo-text\"&gt;&lt;span&gt;Keycloak&lt;/span&gt;&lt;/div&gt;', \"defaultRoles\": [ \"offline_access\" , \"uma_authorization\", \"default-roles-{}\".format(realm) ], \"userManagedAccessAllowed\": \"true\", \"registrationAllowed\": \"true\", \"resetPasswordAllowed\": \"true\", \"editUsernameAllowed\": \"false\", \"loginWithEmailAllowed\": \"true\", \"users\": [{ \"username\": \"{}\".format(keycloak_admin), \"enabled\": \"true\", \"email\": \"{}@email.com\".format(keycloak_admin), \"credentials\": [{ \"type\": \"password\", \"value\": \"{}\".format(keycloak_password) }], \"realmRoles\": [\"offline_access\", \"uma_authorization\", \"default-roles-{}\".format(realm) ], \"clientRoles\": { \"realm-management\": [\"realm-admin\", \"create-client\", \"manage-clients\", \"manage-realm\", \"view-clients\", \"view-realm\", \"view-users\", \"manage-users\"] }, }] }) headers = { 'Authorization': 'bearer {}'.format(auth), 'Content-Type': 'application/json' } response = requests.request(\"POST\", url, headers=headers, data=payload) return response.text realm 삭제def delete_realm(token): \"\"\" realm 생성 \"\"\" url = \"{}/auth/admin/realms/{}\".format(keycloak_url, realm) auth = token headers = { 'Authorization': 'bearer {}'.format(auth), 'Content-Type': 'application/json' } response = requests.request(\"delete\", url, headers=headers) return response.text client 생성def create_sso_client(token): url = \"{}/auth/realms/{}/clients-registrations/default\".format(keycloak_url, realm) auth = token payload = json.dumps({ \"clientId\": \"sso\", \"rootUrl\": \"{url}\".format(application_URL), \"adminUrl\": \"{url}\".format(application_URL), \"redirectUris\": [ \"{url}\".format(application_URL) ], \"webOrigins\": [ \"{url}\".format(application_URL) ], \"implicitFlowEnabled\": \"true\", \"bearerOnly\": \"false\", \"directAccessGrantsEnabled\": \"true\", \"serviceAccountsEnabled\": \"true\", \"attributes\": { \"backchannel.logout.session.required\": \"true\" } }) headers = { 'Authorization': 'bearer {}'.format(auth), 'Content-Type': 'application/json' } response = requests.request(\"POST\", url, headers=headers, data=payload).json() return response get client secretdef generate_secret(token): url = \"{}/auth/admin/realms/{}/clients/{}/client-secret\".format(keycloak_url, realm, client_id) auth = token headers = { 'Authorization': 'bearer {}'.format(auth), 'Content-Type': 'application/json' } response = requests.request(\"POST\", url, headers=headers).json() secret = response.get('value') return secret user 생성, 정보 업데이트def add_user_keycloak(token): url = \"{}/auth/admin/realms/{}/users\".format(keycloak_url, realm) auth = token payload = json.dumps({ \"username\": \"{}\".format(user_id), \"firstName\": \"{}\".format(name), \"email\": \"{}\".format(email), \"enabled\": \"{}\".format(keycloak_user_enable), \"credentials\":[{ \"type\": \"password\", \"value\": \"{}\".format(password), \"temporary\": \"false\" }], }) headers = { 'Authorization': 'bearer {}'.format(auth), 'Content-Type': 'application/json' } \"\"\"user 생성\"\"\" response = requests.request(\"POST\", url, headers=headers, data=payload) \"\"\"정보 업데이트\"\"\" response = requests.request(\"PUT\", url, headers=headers, data=payload) user 삭제def delete_user_keycloak(token): url = \"{}/auth/admin/realms/{}/users/{}\".format(keycloak_url, realm, user_uid) auth = token headers = { 'Authorization': 'bearer {}'.format(auth) } response = requests.request(\"DELETE\", url, headers=headers) return response get user uid\"\"\"keycloak 전체 사용자 정보 리스트\"\"\"def keycloak_users_info(token): url = \"{}/auth/admin/realms/{}/users\".format(keycloak_url, realm) auth = token headers = { 'Authorization': 'bearer {}'.format(auth) } response = requests.request(\"GET\", url, headers=headers).json() return response def get_keycloak_user_uid(token): user_list = keycloak_users_info(token) for user in user_list: id = user.get('username') email = user.get('email') if id == user_id and email == user_origin_eamil: response = user.get('id') return response role mapping (client-role)\"\"\"get client uid\"\"\"def get_client_uid(token): url = \"{}/auth/admin/realms/{}/clients?clientId=realm-management\".format(keycloak_url, realm) auth = token headers = { 'Authorization': 'bearer {}'.format(auth) } client_info = requests.request(\"GET\", url, headers=headers).json() for client_uid in client_info: response = client_uid.get('id') return response\"\"\"get role info\"\"\"def get_role_info(token): url = \"{}/auth/admin/realms/{}/clients/{}/roles?\".format(keycloak_url, realm, client_uid) auth = token headers = { 'Authorization': 'bearer {}'.format(auth) } role_list = requests.request(\"GET\", url, headers=headers).json() for role_info in role_list: role_name = role_info.get('name') if role_name == \"{}\".format(role_name): response = role_info return response\"\"\"role mapping\"\"\"def update_keyclaok_user_role_mapping(token, user_uid, user_admin_yn): client_uid = get_client_uid(token) role_info = get_role_info(token, client_uid) url = \"{}/auth/admin/realms/{}/users/{}/role-mappings/clients/{}\".format(kc_url, kc_realm, user_uid, client_uid) auth = token list = [] list.append(role_info) payload = json.dumps(list) headers = { 'Authorization': 'bearer {}'.format(auth), 'Content-Type': 'application/json', } \"\"\"role mapping\"\"\" response = requests.request(\"POST\", url, headers=headers, data=payload) \"\"\"role mapping 삭제\"\"\" response = requests.request(\"DELETE\", url, headers=headers, data=payload) return response 1.2 Keylock helm 설치 1.2.1 keycloak helm install## 설치(Helm)$ helm repo add bitnami https://charts.bitnami.com/bitnami$ git clone https://github.com/bitnami/charts.git$ cd charts/bitnami/keycloak$ vi values.yamlauth: ## @param auth.createAdminUser Create administrator user on boot ## createAdminUser: true ## @param auth.adminUser Keycloak administrator user ## adminUser: admin ## @param auth.adminPassword Keycloak administrator password for the new user ## adminPassword: \"password\"$ kubectl create namespace keycloak$ helm install keycloak bitnami/keycloak -f values.yaml --namespace keycloak## uninstall$ helm uninstall keycloak --namespace keycloak 1.2.2 values.yaml - docker image 변경## @section Keycloak parametersimage: ##registry: docker.io ##repository: bitnami/keycloak ##tag: 16.1.1-debian-10-r60 registry: {registry} repository: {repository} tag: {tag} 1.2.3 values.yaml - port 변경 ## @section Exposure parametersservice:nodePorts: http: \"{port}\" https: \"{port}\" 1.2.4 values.yaml - db 변경postgresql: enabled: false auth: username: bn_keycloak password: \"\" database: bitnami_keycloak existingSecret: \"\" architecture: standaloneexternalDatabase: host: \"{host}\" port: {port} user: keycloak database: keycloak password: \"{password}\" existingSecret: \"\" existingSecretPasswordKey: \"\" (참고) postgreSQL db 생성# psql 접속psql -U postgres -d postgres# db생성CREATE USER keycloak PASSWORD 'password' SUPERUSER;CREATE DATABASE keycloak;ALTER DATABASE keycloak OWNER TO keycloak;\\password keycloak 1.3 Keylock Page Custom 로그인 페이지의 이미지와 html을 변경 1.3.1 docker build FROM bitnami/keycloak:16.1.1-debian-10-r60COPY keycloak-logo-text.png /opt/bitnami/keycloak/themes/keycloak/login/resources/img/keycloak-logo-text.pngCOPY keycloak-bg.png /opt/bitnami/keycloak/themes/keycloak/login/resources/img/keycloak-bg.pngCOPY login.ftl /opt/bitnami/keycloak/themes/base/login/login.ftldocker build -t {name}:{tag} -f Dockerfile .참고) build가 아닌 cp로 파일을 변경하면 helm install 시 docker entrypoint 때문에 Log도 없이 오류 발생" }, { "title": "[Python] 테스트자동화 - Selenium", "url": "/posts/%ED%85%8C%EC%8A%A4%ED%8A%B8%EC%9E%90%EB%8F%99%ED%99%94_Seleium-%EB%B3%B5%EC%82%AC%EB%B3%B8/", "categories": "Python", "tags": "TDD, Python", "date": "2022-07-23 00:00:00 +0900", "snippet": "Ubuntu - 20.041. Python 테스트자동화 - Selenium웹 어플리케이션을 테스팅 하기에 최적화 되어있으며, 다양한 언어를 제공, 브라우저에서 HTML Tag를 기반으로 파싱하여 다양한 이벤트(Click 등)들을 스크립트로 구현하여 자동으로 이벤트 수행이 가능합니다.1.1 Selenium 설치// pip install// 4.1.0 설치 가능pip install selenium// pipenv install // 4.0.0이후 버전 Locking에서 멈춰있는 오류// 3.0.0버전들은 설치 됨python3.7 -m pipenv —python 3.7 install selenium  1.2 Chrome driver 설치브라우저를 기반으로 테스트를 수행하기 때문에 드라이버 설치가 필요합니다.1.2.1 Chrome 버전 확인 커맨드로 확인google-chrome --version Chrome에서 확인 Chrome실행 - 오른쪽 상단 점 세개 클릭 - 설정클릭 Chrome버전 확인 1.2.2 Chrome driver 설치 버전에 맞는 driver 설치 https://sites.google.com/chromium.org/driver/  1.3 Selenium 사용1.3.1 Code// 사이트접속from selenium import webdriverdriver = webdriver.Chrome(executable_path='chromedriver')driver.get(url='url')// 창모드 최대화면driver.maximize_window()// 찾는 element가 없으면 오류발생driver.find_element ~~~// 해당 element 있을때, 없을때 각각 액션을 주고싶은 경우try: // element가 있을 때 액션 입력except: // element가 없을 때 액션 입력// 찾는 element가 없으면 빈 list returndriver.find_elements ~~~// 해당 element 있을때, 없을때 각각 액션을 주고싶은 경우pw_change_page = self.driver.find_elements ~~if len(pw_change_page) &gt; 0: // element가 있을 때 액션 입력else: // element가 없을 때 액션 입력// Clickdriver.find_element([By.ID](http://by.id/), 'loginForm').click()// 키보드 키 전달Kyes.ENTER, Keys.ARROW_DOWN, Keys.ARROW_LEFT, Keys.ARROW_RIGHT, Keys.ARROW_UP,Keys.BACK_SPACE, Keys.CONTROL, Keys.ALT, Keys.DELETE, Keys.TAB, Keys.SPACE,Keys.SHIFT, Keys.EQUALS, Keys.ESCAPE, Keys.HOME, Keys.INSERT, Keys.PAGE_UP,Keys.PAGE_DOWN,Keys.F1, Keys.F2, Keys.F3, Keys.F4, Keys.F5, Keys.F6, Keys.F7,Keys.F8, Keys.F9 Keys.F10, Keys.F11, Keys.F12// 입력 가능(기존에 입력되어있던 내용이 있으면 그 뒤에 입력 됨)driver.find_element(By.CLASS_NAME, 'content').send_keys('hahaha')// 입력되어있는 내용 삭제driver.find_element(By.CLASS_NAME, 'content').clear()// clear()로 내용이 지워지지 않을 경우driver.find_element_by_id('foo').send_keys(Keys.CONTROL + \"a\");driver.find_element_by_id('foo').send_keys(Keys.DELETE);//새로고침driver.refresh()1.3.2 참고 해당 내용이 있는 페이지가 로딩이 안되있으면 못찾으므로 time.sleep으로 잠깐 멈춰주어야 합니다.import timetime.sleep(20) 같은 이름이 여러개면 첫번째 element를 찾습니다.from [selenium.webdriver.common.by](http://selenium.webdriver.common.by/) import Bydriver.find_element([By.ID](http://by.id/), 'loginForm')driver.find_element(By.XPATH, '//button[text()=\"Some text\"]')driver.find_element(By.LINK_TEXT, 'Continue')driver.find_element(By.PARTIAL_LINK_TEXT, 'Conti')driver.find_element([By.NAME](http://by.name/), 'username')driver.find_element(By.TAG_NAME, 'h1')driver.find_element(By.CLASS_NAME, 'content')driver.find_element(By.CSS_SELECTOR, 'pcontent') ID = “id” XPATH = “xpath” LINK_TEXT = “link text” PARTIAL_LINK_TEXT = “partial link text” NAME = “name” TAG_NAME = “tag name” CLASS_NAME = “class name” CSS_SELECTOR = “css selector”  1.4 Chrome 개발자도구로 Xpath 확인 F12 - Xpath확인할 element 선택 해당 element 내용 우클릭 - Copy - Copy Xpath " }, { "title": "[Docker] Docker Desktop 설치 및 파이썬 스크립트 이미지 생성", "url": "/posts/Docker_Desktop_install_for_Window/", "categories": "Docker", "tags": "Docker, Python", "date": "2022-07-23 00:00:00 +0900", "snippet": "Window 101. Docker Desktop 설치 1.1 Docker desktop 설치1.1.1 Docker Desktop on Windows 다운로드 https://docs.docker.com/desktop/windows/install/ 1.1.2 Docker Desktop for Windows 버튼 클릭 WSL 2 installation is incomplete 오류 발생 시 안내 메시지의 kernel update링크 클릭 후 WSL파일 다운로드, 설치 2. Python 파일 생성2.1 파이썬 파일 생성 test.pyPrint(“Hello World!”)  2.2 Dockerfile 작성 DockerfileFROM python WORKDIR C:\\project\\t3q.ai\\docker_study (py파일과 Dockerfile있는 위치) COPY . . CMD [\"test.py\"] ENTRYPOINT [\"python3\"]  2.3 Docker이미지 생성cd py파일과 Dockerfile있는 위치docker build -t 지정할도커이미지이름 .docker run 지정한도커이미지이름 2.4 Docker이미지 생성 확인docker images " }, { "title": "[Reference & Error] Grafana - Keycloak 연동", "url": "/posts/Grafana_Keycloak_Error_Reference/", "categories": "Reference & Error", "tags": "Monitoring, Grafana, Keycloak", "date": "2022-07-22 00:00:00 +0900", "snippet": " 관련 Post : Grafana Keycloak 연동1. Reference 1.1 Yaml env 환경 변수로 설정docker로 grafana를 띄운 경우yaml에 별도의 환경 변수를 추가하여 설정할 수 있습니다. grafana.ini에서 설정한 값이 환경 변수에 추가되어있으면 환경 변수의 설정 값을 따릅니다. 참고// example- env: - name: GF_&lt;SectionName&gt;_&lt;KeyName&gt; value: &lt;value&gt; 1.2 Grafana 접속 시 keycloak 로그인 화면만 보일 때 Grafana Admin 로그인 방법grafana.ini의 관련 설정을 변경 합니다.# Set to true to attempt login with OAuth automatically, skipping the login screen.# This setting is ignored if multiple OAuth providers are configured.# true일 경우 grafana 로그인 화면을 뛰어넘는 옵션oauth_auto_login = false# Set to true to disable (hide) the login form, useful if you use OAuth, defaults to false# ture일 경우 grafana 로그인 form을 감추는 옵션(유저 정보수정도 함께 가려진다.)disable_login_form = false 1.3 Grafana Grafana home dashborad 설정 - grafana UI 참고1.3.1 좌측 메뉴에서 Dashboards → Browse Tab → 홈 대시 보드로 사용할 대시 보드 선택1.3.2 대시 보드 상단 이름 옆 별 모양 클릭하여 즐겨 찾기 (즐겨 찾기를 해야 Configuration → Preferences Tab → Home Dashboard 선택 가능)1.3.3 좌측 메뉴에서 Configuration → Preferences Tab → Home Dashboard 변경 1.4 keycloak, grafana 조직 권한 mapping 참고 참고조직의 admin 권한 부여는 가능하나 Grafana 전체의 admin권한은 UI에서만 부여 가능합니다.1.4.1 grafana client mapper 생성 clients → {clinet} → Mappers → create1.4.2 grafana client roles 추가 grafana role : 참고 admin, editor, viewer role 추가 clients → {clinet} → Roles → add Role 1.4.3 user 권한 추가 Users → View all users → {user} → Role Mappings Tab → Client Roles → {clinet} 관리자 역할 할당1.4.4 grafana.ini 수정 /etc/grafana/grafana.ini[auth.generic_oauth]role_attribute_path = \"contains(roles[*], 'admin') &amp;&amp; 'Admin' || contains(roles[*], 'editor') &amp;&amp; 'Editor' || 'Viewer'\"1.4.5 확인 admin 권한 부여한 keycloak user로 grafana login → 오른쪽 하단 프로필 → Preferences → Organizations → 변경된 Role 정보 확인 1.5 Grafana Json Import 버튼 작동 안 할 경우 Grafana 8.5.0 버전으로 변경1.5.1 좌측 메뉴에서 Dashboards → Browse Tab → Import → Upload JSON file → Json 파일 선택 overwrite 대신 새로운 dashboard로 추가하려면 json파일 하단 내용을 아래와 같이 변경\"title\": \"{New dashboard name}\", # 새로 추가하는 dashboard의 이름\"uid\": \"\", # 빈값으로\"version\": , # 기존 version +1 1.6 Grafana Table column 편집  1.7 Grafana Data Export CSV  2. Erorr 2.1 Invalid parameter:redirect_uri2.1.1 발생 현상 keycloak 로그인 화면이 출력되지 않고 Invalid parameter:redirect_uri 오류 발생2.1.2 발생 원인 client 설정 시 Valid Redirect URIs에 grafana URL 미 입력 ROOT_URL 미 설정2.1.3 해결 방안 client 설정 시 Valid Redirect URIs에 grafana URL 입력 ROOT_URL 설정** grafana.ini를 수정할 경우 **[server]# The full public facing url you use in browser, used for redirects and emails# If you use reverse proxy and sub path specify full url (with sub path)root_url = {grafana URL}** yaml을 수정할 경우 **- env: - name: GF_SERVER_ROOT_URL value: {grafana URL} 2.2 grafana URL 접속 시 로그인 화면이 아닌 메인 화면으로 접속2.2.1 발생 현상 grafana URL 접속 시 로그인 화면이 아닌 메인 화면으로 접속2.2.2 발생 원인 grafana.ini auth.anonymous 미 설정2.2.3 해결 방안 auth.anonymous 설정** grafana.ini를 수정할 경우 **#################################### Anonymous Auth ######################[auth.anonymous]# enable anonymous accessenabled = false** yaml을 수정할 경우 **- env: - name: GF_AUTH_ANONYMOUS_ENABLED value: \"false\" 2.3 Datasource provisioning error: database is locked2.3.1 발생 현상 Datasource provisioning error: database is locked에러 발생, login 불가2.3.2 발생 원인 grafana db locked2.3.3 해결 방안 sqlite3 backup 명령어 사용# 백업 폴더 생성mkdir -p /backup# grafana.db 복사cp -r /grafana/data/grafana.db /grafana/data/backup/grafana.db# 경로 이동/grafana/data# grafana.db open (sqlite3 CLI)sqlite3 grafana.db# grafana.db .backup (sqlite3 CLI).backup grafana.db.backup# grafana.db 권한 변경chmod 644 grafana.db # grafana 재기동 Dashboard provisining error: Datasource named ${DS_PROMETHEUS} was not found2.4.1 발생 현상 Datasource named ${DS_PROMETHEUS} was not found 에러 발생2.4.2 발생 원인 참고2.4.3 해결 방안 dashboard json configmap 작성 시 ${DS_PROMETHEUS} 로 되어있는 변수 전체를 prometheus로 변경## 변경 전\"datasource\": {\"type\": \"prometheus\",\"uid\": \"${DS_PROMETHEUS}\"## 변경 후\"datasource\": {\"type\": \"prometheus\",\"uid\": \"prometheus\"" }, { "title": "[Linux] Linux Python 설치", "url": "/posts/linux_python_install/", "categories": "Linux", "tags": "Linux, Python", "date": "2022-07-22 00:00:00 +0900", "snippet": "Ubuntu - 20.04들어가기에 앞서…Ubuntu 20.04 에는 Python 3.8이 설치되어 있습니다.해당 Python을 삭제하거나 우선순위를 변경하면 터미널이 열리지 않습니다.절대로… 변경하거나 삭제하지 마세요…// 터미널 안열릴 경우 아래 명령어 입력 후 기존 파이썬 선택sudo update-alternatives –config python3또한make install로 설치 시 /usr/local/bin 에 설치 되나 make uninstall도 없으니 그냥 apt-get으로 설치 하는 것이 건강에 좋습니다.// make install python 삭제(/usr/local/bin에 설치되었을 경우)rm -f /usr/local/bin/python3.7rm -f /usr/local/bin/pip3.7rm -f /usr/local/bin/pydocrm -rf /usr/local/bin/include/python3.7rm -f /usr/local/lib/libpython3.7.arm -rf /usr/local/lib/python3.7rm -f /usr/local/share/man/python3.7.6rm -rf /usr/local/lib/pkgconfigrm -f /usr/local/bin/idlerm -f /usr/local/bin/easy_install-3.7 Ubuntu 20.04 Ptyon 설치 1. apt Python 설치sudo apt updatesudo apt install software-properties-commonsudo add-apt-repository ppa:deadsnakes/ppasudo apt install python3.7 2. Python-dev 버전지정 설치(종속성 설치)sudo apt-get install -y python3.7-dev 3. Python 여러 버전 설치 후 버전 선택사용(윈도우 X)기존 python3.8이 깔려있으므로 앞에 python3.7 -m 안붙히면 python3.8을 사용합니다.python3.7 -m pip install 4. pipenv 버전선택 사용pipenv 버전선택은 —python 3.7 처럼 띄어쓰기 해줘야합니다.python3.7 -m pipenv —python 3.7 install 5. pipenv 환경변수// ~/.bashrc에 등록 // 해당 환경변수 등록 후 가상환경 생성 할 프로젝트 폴더에 들어가서 pipenv install 하면 해당 폴더에 .venv 폴더 생성// 기존은 /root/.local/share/virtualenvs/ 아래에 있음export PIPENV_VENV_IN_PROJECT=1// pipenv install 명령어 실행 후 아래와같은 오류가 나거나 환경변수를 등록했음에도 불구하고 기존의 경로에 생성된다면// root에서 pipenv install 진행No module named 'virtualenv.seed.embed.via_app_data'" }, { "title": "[Linux] LVM(Logical Volume Manager)", "url": "/posts/LVM_Logical_Volume_Manager/", "categories": "Linux", "tags": "Linux", "date": "2022-07-22 00:00:00 +0900", "snippet": "VMware - Centos7 참고LVM(Logical Volume Manager)파티션을 논리적인 개념인 볼륨으로 나눠서 더 유동적으로 디스크의 용량을 관리합니다. 1. PV, PE1.1 PV(Physical Volume) LVM에서 블록 장치를 사용하려면 PV로 초기화를 해야함 즉, 블록 장치 전체 또는 그 블록 장치를 이루고 있는 파티션들을 LVM에서 사용할 수 있게 변환한 것 예를 들어 /dev/sda1, /dev/sda2들을 LVM으로 쓰기위해 PV라는 형식으로 변환한 것 PV는 일정한 크기의 PE(Pysyical Extent)들로 구성 블록 장치 : 블록 단위로 접근하는 스토리지. 예를 들어 대용량 하드 디스크1.2 PE(Physical Extent) PV를 구성하는 일정한 크기의 블록으로 LVM2에서의 기본크기는 4MB, LV(Logical Volume)의 LE(Logical Extent)들과 1:1로 맵핑, 그렇기에 항상 PE와 LE의 크기는 동일, 즉, 아래 그림과 같은 모습 블록 장치(물리적 디스크)의 파티션들을 PV들로 초기화 시킨모습 각각의 PV들은 동일한 크기의 PE들로 구성  2. VG2.1 VG(Volume Group) PV들의 집합으로 LV를 할당할 수 있는 공간. 즉, PV들로 VG를 생성하는 과정은 LV로 할당할 수 있는 디스크 공간의 풀(Pool)을 생성하는것, 사용자는 VG안에서 원하는데로 공간을 쪼개서 LV로 만들 수 있음, 아래 그림과 같이 위에서만든 PV들을 하나의 VG1로 묶은 모습 3. LV, LE3.1 LV(Logical Volume) 사용자가 최종적으로 다루게되는 논리적인 스토리지, 위에서도 언급했지만, LV를 구성하는 LE들이 PV의 PE들과 맵핑하면서 존재3.2 LE(Logical Extent) LV를 구성하는 일정한 크기의 블록으로 LVM2에서 기본크기는 4MB 위에서 언급했지만, 항상 PE와 LE의 크기는 동일 물리적 볼륨을 삭제해도 논리적 볼륨은 살아있으므로 물리적볼륨 삭제 시 데이터는 보존 됩니다./boot 볼륨은 LVM이 인식하지 못하므로 /boot 물리적 볼륨 삭제 시 데이터가 삭제 됩니다. reboot시 리눅스 망가진거 확인 가능 합니다.^^ LVM 확장/용량 추가// 기존 파티션 확인df -Th// 추가된 디스크로 새 파티션 생성fdisk /dev/sda// n -&gt; 파티션을 나누겠다// p -&gt; 기본 파티션으로 하겠다.// 1 -&gt; 파티션 번호// w -&gt; 저장// 현재 잡혀있는 PV 확인pvscan// 새로만든 파티션을 PV로 생성pvcreate /dev/sda1// 현재 잡혀있는 PV 확인pvscan// 생성한 PV(Physical Volume)를 기존 VG(Volume Group)에 추가vgextend VolGroup /dev/sda1// PV(Physical Volume)확인하여 VG(Volume Group)에 추가 되었는지 확인pvscan// 새로 추가한 PV(Physical Volume)를 확인하여 용량 확인pvdisplay /dev/sda1// 늘리고자 하는 LV(Logical Volume)을 확장 lvextend /dev/VolGroup/lv_root -l +2558// 뒤에 숫자는 추가할 용량 byte// VolGroup(VG name), lv_root(PV name)은 pvdisplay /dev/sda1 명령어를 통해 확인 가능// 파티션 확인하면 아직 늘어나지 않은 것을 확인할 수 있음df -Th// 파일시스템 리사이징// etx4resize2fs /dev/VolGroup/lv_root// xfsxfs_growfs /dev/VolGroup/lv_root// 파티션 확인하면 늘어난 것 확인 가능df -Th" }, { "title": "[Kubernetes] Kubernetes install", "url": "/posts/Kbernetes_install/", "categories": "Kubernetes", "tags": "Kubernetes", "date": "2022-07-22 00:00:00 +0900", "snippet": " 관련 Post : Docker installUbuntu - 20.04kubernetes : 1.18.81. Kubernetes 설치 1.Install Kubernetescurl -s [https://packages.cloud.google.com/apt/doc/apt-key.gpg](https://packages.cloud.google.com/apt/doc/apt-key.gpg) | sudo apt-key add -sudo bash -c 'cat &lt;&lt;EOF &gt;/etc/apt/sources.list.d/kubernetes.listdeb [https://apt.kubernetes.io/](https://apt.kubernetes.io/) kubernetes-xenial mainEOF'sudo apt-get update1.1 Disable Security Linux/sbin/setenforce 01.2 Disable SWAPsudo /sbin/swapoff -a1.3 Set IP Forwardecho 1 &gt; sudo /proc/sys/net/ipv4/ip_forward1.4 Network Settingsudo bash -c 'cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOF'sudo sysctl --system1.5 Install Kubernetessudo apt-get install -y kubelet=1.18.8-00 kubeadm=1.18.8-00 kubectl=1.18.8-00sudo apt-mark hold kubelet=1.18.8-00 kubeadm=1.18.8-00 kubectl=1.18.8-001.6 Check Kubernetes versionsudo kubectl version –-client1.7 Start kubeletsudo systemctl daemon-reloadsudo systemctl restart kubeletsudo systemctl enable kubelet2. 단일 클러스터 구성2.1 Setting Environmentswapoff -aecho 1 &gt; /proc/sys/net/ipv4/ip_forward2.2 Kubeadm initsudo kubeadm init --pod-network-cidr 10.244.0.0/16export KUBECONFIG=/etc/kubernetes/admin.conf2.2 Enable Kubectlmkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config2.3 Install network(cni)//Canalkubectl apply -f [https://docs.projectcalico.org/v3.8/manifests/canal.yaml](https://docs.projectcalico.org/v3.8/manifests/canal.yaml)//위브넷kubectl apply -f \"https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\\n')\"2.4 Show Kubernetes Cluster// 마스터노드가 워커노드의 일도 할 수 있도록 해주는 명령어kubectl taint nodes --all node-role.kubernetes.io/master-// 라벨추가(nodeselecter를 지정해놓은것을 yaml에서 확인가능)// nodeselecter - 해당 라벨을 가진 노드에서 실행하겠다kubectl label nodes nodename nodetype=localkubectl get nodekubectl get pods --all-namespaces3. k9s최신버전 확인K9S_VERSION=v0.24.15curl -sL https://github.com/derailed/k9s/releases/download/${K9S_VERSION}/k9s_Linux_x86_64.tar.gz | sudo tar xfz - -C /usr/local/bin k9s// 실행(root권한을 가진 계정으로 접속한게 아니면 sudo를 붙혀 실행해야지 pod, node들 확인 가능)k9s4. Remove Kubernetes//kubeadm reset 안되면//rm -rf /etc/kubernetes/*//rm -rf /root/.kube/sudo kubeadm resetsudo systemctl stop kubeletsudo systemctl stop dockersudo rm -rf /var/lib/cni/sudo rm -rf /var/lib/etcd/sudo rm -rf /var/lib/kubelet/*sudo rm -rf /etc/cni/sudo rm -rf /etc/kubernetessudo rm -rf /root/.kubesudo apt-get remove kubeadmsudo apt-get remove kubeletsudo apt-get remove kubectl5. Error Tip// Ubuntu재시작 시 pods, nod 확인이 안되면서 아래와 같은 오류가 날 경우// did you specify the right host or port? sudo -i swapoff -aexit// strace는 애플리케이션들이 사용하는 system call과 signal 등을 추적해서 // 성능 저하를 일으키는 부분은 없는지, 에러가 나는 부분은 없는지를 확인하는데 사용하는 디버깅 툴strace -eopenat kubectl version" }, { "title": "[Docker] Docker install", "url": "/posts/Docker_install/", "categories": "Docker", "tags": "Docker", "date": "2022-07-22 00:00:00 +0900", "snippet": " 관련 Post : Kubernetes installUbuntu - 20.04docker : 19.03.81. Docker 설치 1.1 Stop Firewalldsudo ufw disable1.2 uninstall old version dockersudo apt-get remove docker docker-engine [docker.io](http://docker.io/) containerd runcsudo apt-get update1.3 SETUP the repositorysudo apt-get install apt-transport-https ca-certificates curl gnupg-agent software-properties-commoncurl -fsSL [https://download.docker.com/linux/ubuntu/gpg](https://download.docker.com/linux/ubuntu/gpg) | sudo apt-key add -sudo apt-key fingerprint 0EBFCD88sudo add-apt-repository \"deb [arch=amd64] [https://download.docker.com/linux/ubuntu](https://download.docker.com/linux/ubuntu) $(lsb_release -cs) stable\"sudo apt-get update1.4 Install Docker//설치가능 도커버전 확인//apt-cache madison docker-ce//apt-cache madison docker-ce-cli//Ubuntu18.04sudo apt-get install docker-ce=5:19.03.8~3-0~ubuntu-bionic docker-ce-cli=5:19.03.8~3-0~ubuntu-bionic [containerd.io](http://containerd.io/)//Ubuntu20.04sudo apt-get install docker-ce=5:19.03.12~3-0~ubuntu-focal docker-ce-cli=5:19.03.12~3-0~ubuntu-focal containerd.io1.5 Check Docker versionsudo docker version2. Docker 설정 참고sudo mkdir /etc/dockercat &lt;&lt;EOF | sudo tee /etc/docker/daemon.json{ \"exec-opts\": [\"native.cgroupdriver=systemd\"], \"log-driver\": \"json-file\", \"log-opts\": { \"max-size\": \"100m\" }, \"storage-driver\": \"overlay2\"}EOFsudo systemctl enable dockersudo systemctl daemon-reloadsudo systemctl restart docker3. Remocve Dockersystemctl stop containerd.servicesudo apt-get purge [containerd.io](http://containerd.io/)sudo apt-get purge docker-cesudo apt autoremove docker-cesudo apt-get purge docker-ce-clisudo rm -rf /var/lib/docker /etc/docker sudo rm /etc/apparmor.d/docker sudo groupdel docker sudo rm -rf /var/run/docker.sock" }, { "title": "[Monitoring] Grafana Keycloak 연동", "url": "/posts/Grafana_keycloak_setting/", "categories": "Monitoring", "tags": "Monitoring, Keycloak, Grafana", "date": "2022-07-21 00:00:00 +0900", "snippet": " 관련 Post: Error &amp; Reference - Grafana Keycloak 연동 1. Keycloakkeycloak은 계정관리 및 access 관리를 제공합니다. Redhat에서 개발한 SSO(single-sign-on) 이 가능한 오픈소스입니다.1.1 기능 SSO 참고) SSO란?Single Sign-On의 약자로 여러 개의 사이트에서 한번의 로그인으로 여러가지 다른 사이트들을 자동적으로 접속하여 이용하는 방법 ID 중개 와 소셜 로그인 (OpenID, SAML, GitHub, Google 등) 관리자 / 계정관리 콘솔 제공 표준 프로토콜 지원(OpenID Connect + OAuth2.0, SAML) Client Adapters (다수의 플랫폼과 프로그래밍 언어가 사용가능한 adapter를 가짐)1.2 용어 OIDC OAuth 가 권한 부여만 다루는 것이라면 OIDC 는 OAuth 를 포함하여 인증과 권한부여를 모두 포함한 것이다. SSO 의 구현을 위한 수단으로 사용된다. Realm 인증, 권한 부여가 적용되는 범위를 나타내는 단위이다. SSO 를 적용한다고 했을때 해당 SSO 가 적용되는 범위는 Realm 단위이다. Client 인증, 권한 부여 행위를 대행하도록 맡길 어플리케이션을 나타내는 단위이다. 그 단위는 웹사이트 혹은 REST API 를 제공하는 서비스도 될 수 있다. 하나의 Realm 에 n개의 Client 를 생성, 관리할 수 있다. User Client 에 인증을 요청할 사용자를 나타낸다. 하나의 Realm 에는 Realm 에 종속된 n개의 User 를 생성하고 관리할 수 있다. 기본적으로 User 는 Username, Email, FirstName, LastName 으로 구성되어 있지만 Custom User Attribute 를 사용하면 사용자가 원하는 속성을 추가할 수 있다. Role User 에게 부여할 권한 내용을 나타낸다. 여기에는 Keycloak 의 REST API 를 사용할 권한을 부여할 수 있고 사용자가 정의한 권한을 부여할 수도 있다.  2. GrafanaGrafana는 시계열데이터를 저장하고 보기 위한 오픈소스 모니터링 툴입니다. 3. Grafana - Keycloak 연동Grafana - 8.5.0Keycloak - 16.1.13.1 Grafana DB변경(SQLite → PostgreSQL)Grafana는 기본적으로 sqlite3를 데이터베이스로 사용한다. SQLite는 “database is locked”오류가 자주 발생하므로 변경하는 것이 좋습니다. PostgreSQL에 grafana DB를 생성합니다.# psql 접속psql -U postgres -d postgres# db생성=========================================CREATE USER grafana PASSWORD 'grafana' SUPERUSER;CREATE DATABASE grafana;ALTER DATABASE grafana OWNER TO grafana;\\password grafana========================================= Grafana.ini의 DB설정을 변경합니다. /etc/grafana/grafana.ini - [database][database]type = postgreshost = ip:portname = grafanauser = grafanapassword = grafana 3.2 Grafana 설정 변경Grafana는 인증을 위해 OAuth를 사용할 수 있으며 grafana.ini파일의 auth.generic_oauth 부분을 수정하여 연동할 수 있습니다.아래의 내용과 같이 grafana.ini 의 설정을 변경합니다.  /etc/grafana/grafana.ini - [server]프록시 뒤에서 Grafana를 제공하는 경우 /login/generic_oauth 콜백 URL이 정확 하려면  root_url 옵션을 설정 해야 합니다.// Edit setting[server]root_url = {grafana_url}// default setting[server];root_url = %(protocol)s://%(domain)s:%(http_port)s/ /etc/grafana/grafana.ini - [auth.generic_oauth]// Edit setting[auth.generic_oauth]enabled = truename = {sign in with {name}}allow_sign_up = trueclient_id = grafanaclient_secret = {keycloak -&gt; clients -&gt; {생성한client} -&gt; credentials -&gt; Secret복사}scopes = openid profileauth_url = {keycloak URL}/auth/realms/{realm name}/protocol/openid-connect/authtoken_url = {keycloak URL}/auth/realms/{realm name}/protocol/openid-connect/tokenapi_url = {keycloak URL}/auth/realms/{realm name}/protocol/openid-connect/userinfotls_skip_verify_insecure = true// default setting[auth.generic_oauth];enabled = false;name = OAuth;allow_sign_up = true;client_id = some_id;client_secret = some_secret;scopes = user:email,read:org;auth_url = https://foo.bar/login/oauth/authorize;token_url = https://foo.bar/login/oauth/access_token;api_url = https://foo.bar/user**;tls_skip_verify_insecure = false enabled - 사용 여부 flase/true name - “Sign in with {name}” 버튼에 들어갈 이름 allow_sign_up - 사용자가 사용자 계정을 등록/생성할 수 없도록 설정 client_id - {client name} client_secret - {keycloak -&gt; clients -&gt; {생성한client} -&gt; credentials -&gt; Secret복사} client 설정 시 Access Type을 **“confidential”로 설정해야 확인 가능* scopes - 인증 범위 auth_url - {keycloak URL}/auth/realms/{realm name}/protocol/openid-connect/auth token_url - {keycloak URL}/auth/realms/{realm name}/protocol/openid-connect/token api_url - {keycloak URL}/auth/realms/{realm name}/protocol/openid-connect/userinfo tls_skip_verify_insecure - true인 경우 SSL/TLS는 서버에서 제공하는 모든 인증서와 해당 인증서의 호스트 이름을 수락 참고 /etc/grafana/grafana.ini - [auth]// Edit setting[auth]signout_redirect_url = {Logout후 redirect 될 url}// default setting[auth];signout_redirect_url = signout_redirect_url - Logout후 redirect 될 url grafana.ini - 추가 설정(선택 사항)[auth]oauth_auto_login = truedisable_login_form = falsedefault_home_dashboard_path = {json 경로}[security]allow_embedding = true oauth_auto_login - True 변경 시 기존 로그인 화면을 뛰어넘고 keycloak 로그인 화면을 기본 화면으로 설정 disable_login_form - True 변경 시 비밀번호 수정을 제한, oauth_auto_login = true와 함께 사용 하면 grfana 로그인 화면에서 keycloak id로만 로그인 가능 default_home_dashboard_path - 지정한 경로에 있는 json 파일을 home dashboard로 지정(dashboard import와 다름) allow_embedding - 해당 설정을 true로 변경해야 dashboard embedding 가능 참고" }, { "title": "[개발 방법론] TDD - 테스트 주도 개발", "url": "/posts/TDD_%ED%85%8C%EC%8A%A4%ED%8A%B8_%EC%A3%BC%EB%8F%84_%EA%B0%9C%EB%B0%9C-%EB%B3%B5%EC%82%AC%EB%B3%B8/", "categories": "개발 방법론", "tags": "TDD", "date": "2022-07-20 00:00:00 +0900", "snippet": "1. Testing소프트웨어가 올바르게 동작하지 않는 경우 금전적 손실, 시간 낭비, 비즈니스 이미지 손상 등 다양한 문제가 발생합니다.Testing은 이러한 문제를 최소화하기 위해 반드시 필요합니다.Test란? 소프트웨어가 요구사항에 의해 개발된 산출물이 요구사항과 부합하는지 여부를 검증하기 위한 작업을 의미합니다. 1.1 Testing - 종류테스트 구성에는 단위 테스트(Unit test), 통합 테스트(Integration test), 승인 테스트(Acceptance test) 등 다양한 테스트가 있습니다. beta testing (베타 테스팅)일반적으로 엔드 유저에 의해 완료되는 테스팅, 프로그램 상용화를 위한 애플리케이션 릴리즈 이전의 최종 테스팅을 의미 합니다. unit testing (유닛 테스팅)프로그램이 통합된 이후에 결합된 기능들을 검증하기 위한 통합 모듈 테스팅, 여기서 모듈은 일반적으로 코드 모듈, 개별 어플리케이션, 네트워크 상의 클라이언트와 서버 애플리케이션 등이 될 수 있습니다. system testing (시스템 테스팅)각각의 요구사항에 대해 전체 시스템이 테스트됩니다. acceptance testing (인수 테스팅)일반적으로 개발된 시스템이 고객이 명세한 요구사항을 충족했는지를 검증하기 위해 사용됩니다.  1.2 Testing - 테스트 기본 원칙각 테스트의 목적과 상황에 맞게 테스트를 구성하는 것도 중요하지만, 테스트의 원칙을 지키는 것이 우선되어야 합니다. 일곱 테스트 원칙(Seven Testing Principles)   테스팅은 결함의 존재를 보여주는 것이다. 완벽한 테스트는 불가능하다. 테스트 구성은 가능한 빠른 시기에 시작한다. 결함은 군집되어 있다. 비슷한 테스트가 반복되면 새로운 결함을 발견할 수 없다. 테스팅은 정황에 의존적이다. 사용되지 않는 시스템이나 사용자의 기대에 부응하지 않는 기능의 결함을 찾고 수정하는 것은 의미가 없다.  F.I.R.S.T 단위 테스트 원칙  Fast 유닛 테스트는 빨라야 한다. Isolated 다른 테스트에 종속적인 테스트는 절대로 작성하지 않는다. Repeatable 테스트는 실행할 때마다 같은 결과를 만들어야 한다. Self-validating 테스트는 스스로 결과물이 옳은지 그른지 판단할 수 있어야 한다. 특정 상태를 수동으로 미리 만들어야 동작하는 테스트 등은 작성하지 않는다. Timely 유닛 테스트는 프로덕션 코드가 테스트를 성공하기 직전에 구성되어야 한다. 테스트 주도 개발(TDD) 방법론에 적합한 원칙이지만 실제로 적용되지 않는 경우도 있다.    2. TDD(Test-Driven-Development)TDD란 매우 짧은 개발 사이클을 반복하는 소프트웨어 개발 프로세스 중 하나입니다.개발자는 먼저 요구사항을 검증하는 자동화된 테스트 케이스를 작성하고, 그 테스트 케이스를 통과하기 위한 최소한의 코드를 생성한 뒤 마지막으로 작성한 코드를 표준에 맞도록 리팩토링합니다. 2.1 TDD - 메인 프로세스TDD의 메인 프로세스는 다음과 같이 3가지 단계로 나눌 수 있습니다. RED - 테스트 실패실패하는 것이 확인 되어야, 테스트가 검증력을 가진다고 신뢰할 수 있습니다. 실패의 이유는 운영 코드가 아직 변경되지 않았기 때문이어야 하며, 테스트 코드의 문제이면 안 됩니다. 구체적인 하나의 요구사항을 검증하는 하나의 테스트를 추가한다. 추가된 테스트가 실패하는지 확인한다. GREEN - 테스트 성공TDD에서는 테스트 성공을 위한 최소한의 코드 그 이상을 변경하거나 추가하면 안 됩니다. 테스트 되지 않은 코드가 중간에 추가되면, 이후 리팩토링 등의 다른 프로세스에서 어떤 부작용을 가져올지 알 수 없기 때문입니다. 추가된 테스트를 포함하여, 모든 테스트가 성공하게끔 운영 코드를 변경한다. 테스트의 성공은 모든 요구사항을 만족했음을 의미한다. 테스트 성공을 위한 최소한의 코드 변경만 진행한다. REFACTOR - 리팩토링 코드베이스를 정리한다. 인터페이스 뒤에 숨어 있는 구현 설계를 개선한다. 가독성, 적용성, 성능을 고려한다.  2.2 TDD - 기존의 개발 방식과 TDD 개발 방식의 특징 기존 개발 방식 테스트가 실패하게 되면 매번 설계단계로 다시 돌아오게 되어 많은 시간이 소요된다. 작은 기능 수정에도 모든 부분을 함께 테스트해야하기 때문에 테스트 비용이 증가된다. TDD 개발 방식 일반 개발 방식과달리 실패테스트 코드를 먼저 작성하고, 테스트 코드를 성공하기 위한 코드를 작성한다 필요하다면 재설계 후에 테스트 코드에 바로 적용할 수 있기 때문에 설계의 개선이 쉽고 빠르다. 테스트코드에서 필요한 예외 사항들에대한 테스트를 추가하는 반복적인 단계가 진행되면서 코드의 버그가 줄어든다. " }, { "title": "[Python] 단위 테스트 - unittest", "url": "/posts/Test_case/", "categories": "Python", "tags": "TDD, Python", "date": "2022-07-20 00:00:00 +0900", "snippet": "1. Python 단위테스트 프레임워크 unittestTest case란 일련의 입력값과 기대되는 출력값의 목록 입니다.내가 개발한 서비스가 올바르게 동작하는지 확인하기 위해서는 테스트가 필요합니다.unittest 모듈은 Python 단위 테스트 프레임워크로 다른 언어와 달리 기본적으로 언어에 내장되어 있기 때문에 파이썬만 설치가 되어 있다면 바로 모듈을 불러와서(import) 사용할 수 있습니다. 참고) 언어별 단위테스트 프레임 워크 Java - JUnitPython - unittestJavaScript - Jest, Mocha1.1 unittest에 포함된 주요 개념 TestCase unittest 프레임 워크의 테스트 조직의 기본 단위입니다. Fixture 테스트함수의 전 또는 후에 실행합니다. 테스트가 실행되기 전에 테스트 환경이 예상 된 상태에 있는지 확인하는 데 사용합니다. 테스트 전에 데이터베이스 테이블을 만들거나 테스트 후에 사용한 리소스를 정리하는데 사용합니다. assertion unittest가 테스트가 통과하는지 또는 실패 하는지를 결정합니다. bool test, 객체의 적합성, 적절한 예외 발생 등 다양한 점검을 할 수 있습니다. assertion이 실패하면 테스트 함수가 실패합니다. 1.2 unittest example calc.utils.pydef plus_red(a,b): return 3def plus_green(a,b): return a + b test_calc.pyimport unittestfrom calc_utils import plus_red, plus_greenclass Test_calc_plus(unittest.TestCase): def test_calc_utils_red(self): a = 1 b = 2 result = plus_red(a,b) true_result = 3 self.assertEqual(result, true_result) def test_calc_utils_red_2(self): a = 3 b = 2 result = plus_red(a,b) true_result = 5 self.assertEqual(result, true_result) def test_calc_utils_green(self): a = 3 b = 2 result = plus_green(a,b) true_result = 5 self.assertEqual(result, true_result) if name == 'main': unittest.main()" }, { "title": "[Monitoring] 쿠버네티스 모니터링 - Prometheus", "url": "/posts/Kubernetes_monitoring_Prometheus/", "categories": "Monitoring", "tags": "Monitoring, Kubernetes, Prometheus", "date": "2022-07-20 00:00:00 +0900", "snippet": "1. PrometheusPrometheus는 현재 쿠버네티스 상에서 가장 많이 사용되고 있는 오픈 소스 기반 모니터링 시스템이며, 쿠버네티스 클러스터 및 컨테이너들를 손쉽게 모니터링이 가능합니다. PromQL 쿼리 PromQL 쿼리를 사용하여 외부 API나 프로메테우스 웹콘솔을 이용해 서빙 가능합니다. 그라파나 등과 통합하여 대쉬보드 구성합니다.  Alert manager alert를 전달받아 이를 적절한 포맷으로 가공하여 notify Email, slack 에 알람 가능합니다.  Service Discovery Pod증가, Worker Node 증가 등 모니터링 대상 변경 탐지 kubernetes를 service discovery로 사용할 경우 kube-apiserver를 통해 모니터링해야할 타겟 서비스의 목록을 받아옵니다.  Push gateway 필요한 경우에만 떠 있다가 작업이 끝나면 사라지는 배치, 스케줄 작업 등은 Push gateway를 통해 지표를 받아옵니다. Metric Data를 보관하고 있다가 Prometheus 서버가 Pull 작업을 하면, 보관하고 있던 Metric Data를 리턴합니다.  매트릭 저장 일정시간마다 매트릭 수집 HDD/SDD 에 저장합니다.  Exporter exporter 는 Prometheus가 pull 방식으로 데이터를 수집할 수 있도록 매트릭을 노출하는 agent, export는 서버들로부터 매트릭을 수집해 /metrics HTTP endpoint를 제공하면 Prometheus 는 exporter 가 열어놓은 HTTP endpoint 로 GET 요청을 날려 메트릭을 수집(Pull 방식) 모니터링 대상이 프로메테우스의 데이터 포맷을 지원하지 않는 경우 별도의 에이전트( Exporter)를 설치해야 지표를 얻어올 수 있습니다. java나 node.js와 같은 사용자 애플리케이션의경우에는 Exporter를 사용하지 않고, 프로메테우스클라이언트 라이브러리를 사용하게 되면 바로 지표를 프로메테우스 서버로 보낼 수 있습니다. exporter의 종류에는 node-exporter, mysql- exporter, nginx-exporter, redis-exporter 등이 있습니다.   1.1 Prometheus - 쿠버네티스 모니터링 시스템으로 많이 쓰이는 이유Prometheus는 pull방식으로 매트릭을 수집하므로 쿠버네티스 환경처럼 어플리케이션의 단위가 작고 모니터링 대상도 동적으로 변경될때에는 pull 방식이 용이합니다. 1.2 Prometheus - 모니터링 영역(시계열 데이터) 클러스터에 대한 정보 Pod, Deployment, Ingress 정보 등 클러스터(Cluster)를 이루는 구성 요소의 정보 노드에 대한 정보 클러스터를 이루는 각각의 서버, 노드(Node)의 실제 CPU, 메모리, 트래픽 등의 사용량 리소스 사용량에 대한 정보 Node, Pod 등의 리소스 사용량 직접 만든 서비스에 대한 정보 웹 서버의 페이지뷰, 회원가입 양 등 수치로 표현할 수 있는 모든 것 1.3 Prometheus - 장/단점장점 설정파일을 프로메테우스 서버 설정파일만 변경한 후 node-exporter는 배포만 하면 되기 때문에 관리자 입장에서 시스템 운영이 용이 일정 간격마다 데이터를 수집하기 때문에 저사양의 Spec. 으로도 모니터링 시스템 구축이 가능 CPU/메모리/파일시스템 현황, 컨테이너 현황 등 특정 데이터의 흐름을 파악하는데 용이 단점 많은 이벤트가 발생하는 시스템을 모니터링 하는데는 적합하지 않음 이벤트 수집, 배치 작업 등 단발적으로 발생하는 업무 모니터링을 할 때는 적합하지 않음  2. Pull &amp; Push push - 에이전트가 모니터링 서버에게 데이터를 보내는 것 일반적으로 push 방식은 Host -&gt; Data Backend로 전송하기 때문에, Data Backend를 변경할 시 Host마다 설정 파일 모두 변경 필요 Data Backend에 장애가 발생했을 때에도 아무 소용없는 push가 이루어지기에 트래픽에 과부하 pull - 모니터링 서버가 데이터를 에이전트에게 접근하여 가져오는 것 대상 애플리케이션의 Exporter Endpoint로부터 데이터를 scrape 해오는 방식 모니터링 설정이 Data Backend에서 관리되기 때문에 변경이 쉬움 Prometheus에 장애가 발생해도 애플리케이션 자체에 영향 없음 " }, { "title": "[AWS] SSH-Putty-터널링", "url": "/posts/aws_ssh_%ED%84%B0%EB%84%90%EB%A7%81/", "categories": "AWS", "tags": "AWS, SSH, BASTION", "date": "2022-07-20 00:00:00 +0900", "snippet": " 내가 구현할 목표: AWS 환경은 바스티온 =&gt; WEB =&gt; WAS 로 구현되어 있다.해당 환경에서 바스티온을 통해 터널링을 설정하여 WAS 로 접근하기가 목표이다. 참고 바스티온이란 ? https://err-bzz.oopy.io/f5616e26-79ca-4167-b2eb-140de69b9b54 본문 우선 세션에서 접근할 바스티온 Public Ip 를 host name 에 기입한다. ssh 접근을 위한 서버 전용 ppk 키를 Private key file for authentication 에 넣는다. Tunnels 로 간 후 Source Port 에는 서버로 접근가능한 포트와Destination 에는 접근할 서버의 private Ip 와 포트를 함께 넣는다.ex) 123.123.123.123:{port number} 다 적었으면 Add 버튼을 눌러 준 후 Open 으로 연결시킨다. 연결이 된다면 해당 화면처럼 연결된 결과가 나오면서 바스티온 ( public Ip ) 서버로 처음 접근이 완료된다. 내가 접근하려 했던 실제 터널링 주소는 어떻게 접근하는가? =&gt; 바스티온 서버를 켜놓은 채Putty new session 을 켠 후 세션 host name 부분에 ec2-user@localhost 를 적은 뒤2번에 서버 전용 ppk 키를 Private key file for authentication 넣는 과정을 다시 해준 후 Open 을 한다.결과적으로 쁘띠 창은 2개, 1개는 바스티온 서버이며 터널링을 통해 ec2-user@localhost 로 open 한실제 접근하려한 private Ip 서버를 가진 Putty 창이 켜진것을 확인할 수 있다. 참고: 해당 과정에서 서버연결할 때에 창에서 login as: 를 볼 수 있는데 당황하지 말고ec2-user 를 기입해 주면 된다. 해당 과정이 귀찮다면Rlogin 란에 local username 에 ec2-user 를 넣어주면 된다.이상 AWS 의 바스티온 을 통한 서버접근 방식을 마무리 하겠습니다.해당 로직을 이해하기 위한 환경로직은 구성된 환경 마다 다르기 때문에 표현하지 않겠습니다.그리고 AWS OS 이미지 AMI 마다 정의되는 ID 가 다르므로 (정확한 정보인지는 모르겠습니다. )login id 적으실 때 참고하시면 좋을 것 같습니다. 이상입니다." } ]
